{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH='D:\\数据科学\\\\1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, ViTModel\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class AppleDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    def __init__(self, file,data_path):\n",
    "        \"\"\"Method to initilaize variables.\"\"\"\n",
    "        self.data=pd.read_csv(file)\n",
    "        self.data_path=data_path\n",
    "        self.image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "    def __getitem__(self, index):\n",
    "        feature1,feature2,label=self.data['couple1'][index],self.data['couple2'][index],self.data['label1'][index]\n",
    "        img_path = os.path.join(self.data_path, feature1)\n",
    "        img_path1 = os.path.join(self.data_path, feature2)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img1 = Image.open(img_path1).convert(\"RGB\")\n",
    "        x = self.image_processor(img, return_tensors=\"pt\")\n",
    "        y = self.image_processor(img1, return_tensors=\"pt\")\n",
    "        return x['pixel_values'], y['pixel_values'],label\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_set = AppleDataset('train.csv', DATA_PATH)\n",
    "train_loader = DataLoader(train_set, batch_size=10)\n",
    "test_set=AppleDataset('test_data.csv', DATA_PATH)\n",
    "test_loader = DataLoader(train_set, batch_size=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class dot_attention(nn.Module):\n",
    "    \"\"\" 点积注意力机制\"\"\"\n",
    "\n",
    "    def __init__(self, attention_dropout=0.0):\n",
    "        super(dot_attention, self).__init__()\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v, scale=None, attn_mask=None):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param q:\n",
    "        :param k:\n",
    "        :param v:\n",
    "        :param scale:\n",
    "        :param attn_mask:\n",
    "        :return: 上下文张量和attention张量。\n",
    "        \"\"\"\n",
    "        attention = torch.bmm(q, k.transpose(1, 2))\n",
    "        if scale:\n",
    "            attention = attention * scale        # 是否设置缩放\n",
    "        if attn_mask:\n",
    "            attention = attention.masked_fill(attn_mask, -np.inf)     # 给需要mask的地方设置一个负无穷。\n",
    "        # 计算softmax\n",
    "        attention = self.softmax(attention)\n",
    "        # 添加dropout\n",
    "        attention = self.dropout(attention)\n",
    "        # 和v做点积。\n",
    "        context = torch.bmm(attention, v)\n",
    "        return context, attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" 多头自注意力\"\"\"\n",
    "    def __init__(self, model_dim=1024, num_heads=4, dropout=0.0):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.dim_per_head = model_dim//num_heads   # 每个头的维度\n",
    "        self.num_heads = num_heads\n",
    "        self.linear_k = nn.Linear(model_dim, self.dim_per_head * num_heads)\n",
    "        self.linear_v = nn.Linear(model_dim, self.dim_per_head * num_heads)\n",
    "        self.linear_q = nn.Linear(model_dim, self.dim_per_head * num_heads)\n",
    "\n",
    "        self.dot_product_attention = dot_attention(dropout)\n",
    "\n",
    "        self.linear_final = nn.Linear(model_dim, model_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(model_dim)         # LayerNorm 归一化。\n",
    "\n",
    "    def forward(self, key, value, query, attn_mask=None):\n",
    "        residual = query\n",
    "        dim_per_head = self.dim_per_head\n",
    "        num_heads = self.num_heads\n",
    "        batch_size = key.size(0)\n",
    "\n",
    "        # 线性映射。\n",
    "        key = self.linear_k(key)\n",
    "        value = self.linear_v(value)\n",
    "        query = self.linear_q(query)\n",
    "\n",
    "        # 按照头进行分割\n",
    "        key = key.view(batch_size * num_heads, -1, dim_per_head)\n",
    "        value = value.view(batch_size * num_heads, -1, dim_per_head)\n",
    "        query = query.view(batch_size * num_heads, -1, dim_per_head)\n",
    "\n",
    "        if attn_mask:\n",
    "            attn_mask = attn_mask.repeat(num_heads, 1, 1)\n",
    "\n",
    "        # 缩放点击注意力机制\n",
    "        scale = (key.size(-1) // num_heads) ** -0.5\n",
    "        context, attention = self.dot_product_attention(query, key, value, scale, attn_mask)\n",
    "\n",
    "        # 进行头合并 concat heads\n",
    "        context = context.view(batch_size, -1, dim_per_head * num_heads)\n",
    "\n",
    "        # 进行线性映射\n",
    "        output = self.linear_final(context)\n",
    "\n",
    "        # dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # 添加残差层和正则化层。\n",
    "        output = self.layer_norm(residual + output)\n",
    "\n",
    "        return output, attention\n",
    "\n",
    "\n",
    "# q = torch.ones((1, 17, 400))\n",
    "# k = torch.ones((1, 17, 400))\n",
    "# v = k\n",
    "# mutil_head_attention = MultiHeadAttention()\n",
    "# output, attention = mutil_head_attention(q, k, v)\n",
    "# print(\"context:\", output.shape)\n",
    "# print(\"attention:\", attention.size(), attention)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the final output: torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from moe import SparseMoE\n",
    "class VIT_Couple(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(VIT_Couple, self).__init__()\n",
    "        self.model=ViTModel.from_pretrained(\"google/vit-large-patch16-224-in21k\")\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.fc2 = nn.Linear(512, 100)\n",
    "        self.fc3 = nn.Linear(100, 2)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.sparse_moe = SparseMoE(512, 3, 2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.multi_head_attention= MultiHeadAttention()\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        x=x.view(x.shape[0],x.shape[2],x.shape[3],x.shape[4])#3,3,224,224\n",
    "        y=y.view(y.shape[0],y.shape[2],y.shape[3],y.shape[4])\n",
    "        x = self.model(x).pooler_output#1, 197, 768\n",
    "        y = self.model(y).pooler_output#1, 197, 768\n",
    "        x=x.view(x.shape[0],1,x.shape[1])\n",
    "        y=y.view(y.shape[0],1,y.shape[1])\n",
    "        pos=torch.concat((x,y),dim=1)# 1 2 768\n",
    "        pos, attention = self.multi_head_attention(pos, pos, pos)# 1 2 768\n",
    "        x=x.view(pos.shape[0],-1)\n",
    "        pos=self.fc1(x)\n",
    "        # pos=self.sparse_moe(pos)\n",
    "        pos = self.dropout(pos)\n",
    "        pos = F.relu(pos)\n",
    "        pos=self.fc2(pos)\n",
    "        pos = F.relu(pos)\n",
    "        pos=self.fc3(pos)\n",
    "\n",
    "        return pos\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# from transformers import ViTImageProcessor, ViTModel\n",
    "# from PIL import Image\n",
    "# import requests\n",
    "# url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "# processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "# model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "# inputs = processor(images=image, return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "# last_hidden_states = outputs.pooler_output\n",
    "# last_hidden_states.shape# 1 768"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data1,data2, labels) in enumerate(train_loader):\n",
    "        data1 = data1.to('cuda')\n",
    "        data2 = data2.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        outputs = model(data1,data2)\n",
    "        # 计算损失\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        # 打印训练信息\n",
    "        if batch_idx % 1 == 0:\n",
    "            print('Epoch: {}, Batch: {}, Loss: {:.4f}'.format(\n",
    "                epoch, batch_idx, loss.item()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, data1,labels in test_loader:\n",
    "            # 将数据和标签移动到 GPU\n",
    "            data = data.to('cuda')\n",
    "            data1 = data1.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "            # 预测\n",
    "            outputs = model(data,data1)\n",
    "            # 计算准确率\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            print('predicted',predicted)\n",
    "            print('labels',labels)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            print((predicted == labels).sum().item())\n",
    "    print(correct)\n",
    "    print(total)\n",
    "    print('Accuracy: {:.2f}%'.format(100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 0.6874\n",
      "Epoch: 0, Batch: 1, Loss: 0.6888\n",
      "Epoch: 0, Batch: 2, Loss: 0.6876\n",
      "Epoch: 0, Batch: 3, Loss: 0.7073\n",
      "Epoch: 0, Batch: 4, Loss: 0.6884\n",
      "Epoch: 0, Batch: 5, Loss: 0.6871\n",
      "Epoch: 0, Batch: 6, Loss: 0.7055\n",
      "Epoch: 0, Batch: 7, Loss: 0.6703\n",
      "Epoch: 0, Batch: 8, Loss: 0.6685\n",
      "Epoch: 0, Batch: 9, Loss: 0.6374\n",
      "Epoch: 0, Batch: 10, Loss: 0.6587\n",
      "Epoch: 0, Batch: 11, Loss: 0.6805\n",
      "Epoch: 0, Batch: 12, Loss: 0.6642\n",
      "Epoch: 0, Batch: 13, Loss: 0.7462\n",
      "Epoch: 0, Batch: 14, Loss: 0.6626\n",
      "Epoch: 0, Batch: 15, Loss: 0.6039\n",
      "Epoch: 0, Batch: 16, Loss: 0.8106\n",
      "Epoch: 0, Batch: 17, Loss: 0.7721\n",
      "Epoch: 0, Batch: 18, Loss: 0.7677\n",
      "Epoch: 0, Batch: 19, Loss: 0.6798\n",
      "Epoch: 0, Batch: 20, Loss: 0.8375\n",
      "Epoch: 0, Batch: 21, Loss: 0.6094\n",
      "Epoch: 0, Batch: 22, Loss: 0.6837\n",
      "Epoch: 0, Batch: 23, Loss: 0.7527\n",
      "Epoch: 0, Batch: 24, Loss: 0.7120\n",
      "Epoch: 0, Batch: 25, Loss: 0.6605\n",
      "Epoch: 0, Batch: 26, Loss: 0.6327\n",
      "Epoch: 0, Batch: 27, Loss: 0.7393\n",
      "Epoch: 0, Batch: 28, Loss: 0.6740\n",
      "Epoch: 0, Batch: 29, Loss: 0.6999\n",
      "Epoch: 0, Batch: 30, Loss: 0.6407\n",
      "Epoch: 0, Batch: 31, Loss: 0.7028\n",
      "Epoch: 0, Batch: 32, Loss: 0.7340\n",
      "Epoch: 0, Batch: 33, Loss: 0.7463\n",
      "Epoch: 0, Batch: 34, Loss: 0.6798\n",
      "Epoch: 0, Batch: 35, Loss: 0.6729\n",
      "Epoch: 0, Batch: 36, Loss: 0.7399\n",
      "Epoch: 0, Batch: 37, Loss: 0.6900\n",
      "Epoch: 0, Batch: 38, Loss: 0.6938\n",
      "Epoch: 0, Batch: 39, Loss: 0.6829\n",
      "Epoch: 0, Batch: 40, Loss: 0.7327\n",
      "Epoch: 0, Batch: 41, Loss: 0.6984\n",
      "Epoch: 0, Batch: 42, Loss: 0.7076\n",
      "Epoch: 0, Batch: 43, Loss: 0.6933\n",
      "Epoch: 0, Batch: 44, Loss: 0.6982\n",
      "Epoch: 0, Batch: 45, Loss: 0.6742\n",
      "Epoch: 0, Batch: 46, Loss: 0.7060\n",
      "Epoch: 0, Batch: 47, Loss: 0.6895\n",
      "Epoch: 0, Batch: 48, Loss: 0.7099\n",
      "Epoch: 0, Batch: 49, Loss: 0.6785\n",
      "Epoch: 0, Batch: 50, Loss: 0.6865\n",
      "Epoch: 0, Batch: 51, Loss: 0.6779\n",
      "Epoch: 0, Batch: 52, Loss: 0.6603\n",
      "Epoch: 0, Batch: 53, Loss: 0.6904\n",
      "Epoch: 0, Batch: 54, Loss: 0.7037\n",
      "Epoch: 0, Batch: 55, Loss: 0.6748\n",
      "Epoch: 0, Batch: 56, Loss: 0.7128\n",
      "Epoch: 0, Batch: 57, Loss: 0.7030\n",
      "Epoch: 0, Batch: 58, Loss: 0.6891\n",
      "Epoch: 0, Batch: 59, Loss: 0.6932\n",
      "Epoch: 0, Batch: 60, Loss: 0.6770\n",
      "Epoch: 0, Batch: 61, Loss: 0.6764\n",
      "Epoch: 0, Batch: 62, Loss: 0.7182\n",
      "Epoch: 0, Batch: 63, Loss: 0.6827\n",
      "Epoch: 0, Batch: 64, Loss: 0.6921\n",
      "Epoch: 0, Batch: 65, Loss: 0.6887\n",
      "Epoch: 0, Batch: 66, Loss: 0.7067\n",
      "Epoch: 0, Batch: 67, Loss: 0.7282\n",
      "Epoch: 0, Batch: 68, Loss: 0.7143\n",
      "Epoch: 0, Batch: 69, Loss: 0.7046\n",
      "Epoch: 0, Batch: 70, Loss: 0.6823\n",
      "Epoch: 0, Batch: 71, Loss: 0.7029\n",
      "Epoch: 0, Batch: 72, Loss: 0.6807\n",
      "Epoch: 0, Batch: 73, Loss: 0.6781\n",
      "Epoch: 0, Batch: 74, Loss: 0.6911\n",
      "Epoch: 0, Batch: 75, Loss: 0.6978\n",
      "Epoch: 0, Batch: 76, Loss: 0.7101\n",
      "Epoch: 0, Batch: 77, Loss: 0.6990\n",
      "Epoch: 0, Batch: 78, Loss: 0.7069\n",
      "Epoch: 0, Batch: 79, Loss: 0.6942\n",
      "Epoch: 0, Batch: 80, Loss: 0.6853\n",
      "Epoch: 0, Batch: 81, Loss: 0.7048\n",
      "Epoch: 0, Batch: 82, Loss: 0.6928\n",
      "Epoch: 0, Batch: 83, Loss: 0.7236\n",
      "Epoch: 0, Batch: 84, Loss: 0.6970\n",
      "Epoch: 0, Batch: 85, Loss: 0.6965\n",
      "Epoch: 0, Batch: 86, Loss: 0.6768\n",
      "Epoch: 0, Batch: 87, Loss: 0.6626\n",
      "Epoch: 0, Batch: 88, Loss: 0.6785\n",
      "Epoch: 0, Batch: 89, Loss: 0.7019\n",
      "Epoch: 0, Batch: 90, Loss: 0.7330\n",
      "Epoch: 0, Batch: 91, Loss: 0.6698\n",
      "Epoch: 0, Batch: 92, Loss: 0.6553\n",
      "Epoch: 0, Batch: 93, Loss: 0.6891\n",
      "Epoch: 0, Batch: 94, Loss: 0.6737\n",
      "Epoch: 0, Batch: 95, Loss: 0.7075\n",
      "Epoch: 0, Batch: 96, Loss: 0.7107\n",
      "Epoch: 0, Batch: 97, Loss: 0.6663\n",
      "Epoch: 0, Batch: 98, Loss: 0.6969\n",
      "Epoch: 0, Batch: 99, Loss: 0.6441\n",
      "Epoch: 0, Batch: 100, Loss: 0.7072\n",
      "Epoch: 0, Batch: 101, Loss: 0.7065\n",
      "Epoch: 0, Batch: 102, Loss: 0.7219\n",
      "Epoch: 0, Batch: 103, Loss: 0.7173\n",
      "Epoch: 0, Batch: 104, Loss: 0.7246\n",
      "Epoch: 0, Batch: 105, Loss: 0.7727\n",
      "Epoch: 0, Batch: 106, Loss: 0.6575\n",
      "Epoch: 0, Batch: 107, Loss: 0.7221\n",
      "Epoch: 0, Batch: 108, Loss: 0.7153\n",
      "Epoch: 0, Batch: 109, Loss: 0.7075\n",
      "Epoch: 0, Batch: 110, Loss: 0.7225\n",
      "Epoch: 0, Batch: 111, Loss: 0.6980\n",
      "Epoch: 0, Batch: 112, Loss: 0.7284\n",
      "Epoch: 1, Batch: 0, Loss: 0.6735\n",
      "Epoch: 1, Batch: 1, Loss: 0.6740\n",
      "Epoch: 1, Batch: 2, Loss: 0.6738\n",
      "Epoch: 1, Batch: 3, Loss: 0.6717\n",
      "Epoch: 1, Batch: 4, Loss: 0.6372\n",
      "Epoch: 1, Batch: 5, Loss: 0.6794\n",
      "Epoch: 1, Batch: 6, Loss: 0.6979\n",
      "Epoch: 1, Batch: 7, Loss: 0.6582\n",
      "Epoch: 1, Batch: 8, Loss: 0.6572\n",
      "Epoch: 1, Batch: 9, Loss: 0.6354\n",
      "Epoch: 1, Batch: 10, Loss: 0.6714\n",
      "Epoch: 1, Batch: 11, Loss: 0.6617\n",
      "Epoch: 1, Batch: 12, Loss: 0.6491\n",
      "Epoch: 1, Batch: 13, Loss: 0.7083\n",
      "Epoch: 1, Batch: 14, Loss: 0.6600\n",
      "Epoch: 1, Batch: 15, Loss: 0.6157\n",
      "Epoch: 1, Batch: 16, Loss: 0.7679\n",
      "Epoch: 1, Batch: 17, Loss: 0.7422\n",
      "Epoch: 1, Batch: 18, Loss: 0.7324\n",
      "Epoch: 1, Batch: 19, Loss: 0.6698\n",
      "Epoch: 1, Batch: 20, Loss: 0.7622\n",
      "Epoch: 1, Batch: 21, Loss: 0.6135\n",
      "Epoch: 1, Batch: 22, Loss: 0.6880\n",
      "Epoch: 1, Batch: 23, Loss: 0.7327\n",
      "Epoch: 1, Batch: 24, Loss: 0.6939\n",
      "Epoch: 1, Batch: 25, Loss: 0.6642\n",
      "Epoch: 1, Batch: 26, Loss: 0.6353\n",
      "Epoch: 1, Batch: 27, Loss: 0.7268\n",
      "Epoch: 1, Batch: 28, Loss: 0.6881\n",
      "Epoch: 1, Batch: 29, Loss: 0.6917\n",
      "Epoch: 1, Batch: 30, Loss: 0.6418\n",
      "Epoch: 1, Batch: 31, Loss: 0.6824\n",
      "Epoch: 1, Batch: 32, Loss: 0.7159\n",
      "Epoch: 1, Batch: 33, Loss: 0.7311\n",
      "Epoch: 1, Batch: 34, Loss: 0.6631\n",
      "Epoch: 1, Batch: 35, Loss: 0.6816\n",
      "Epoch: 1, Batch: 36, Loss: 0.7257\n",
      "Epoch: 1, Batch: 37, Loss: 0.7047\n",
      "Epoch: 1, Batch: 38, Loss: 0.6642\n",
      "Epoch: 1, Batch: 39, Loss: 0.6664\n",
      "Epoch: 1, Batch: 40, Loss: 0.7217\n",
      "Epoch: 1, Batch: 41, Loss: 0.6812\n",
      "Epoch: 1, Batch: 42, Loss: 0.6895\n",
      "Epoch: 1, Batch: 43, Loss: 0.6791\n",
      "Epoch: 1, Batch: 44, Loss: 0.6928\n",
      "Epoch: 1, Batch: 45, Loss: 0.6605\n",
      "Epoch: 1, Batch: 46, Loss: 0.7066\n",
      "Epoch: 1, Batch: 47, Loss: 0.6766\n",
      "Epoch: 1, Batch: 48, Loss: 0.7080\n",
      "Epoch: 1, Batch: 49, Loss: 0.6880\n",
      "Epoch: 1, Batch: 50, Loss: 0.6710\n",
      "Epoch: 1, Batch: 51, Loss: 0.6615\n",
      "Epoch: 1, Batch: 52, Loss: 0.6655\n",
      "Epoch: 1, Batch: 53, Loss: 0.6843\n",
      "Epoch: 1, Batch: 54, Loss: 0.7100\n",
      "Epoch: 1, Batch: 55, Loss: 0.6549\n",
      "Epoch: 1, Batch: 56, Loss: 0.6901\n",
      "Epoch: 1, Batch: 57, Loss: 0.6970\n",
      "Epoch: 1, Batch: 58, Loss: 0.6760\n",
      "Epoch: 1, Batch: 59, Loss: 0.6759\n",
      "Epoch: 1, Batch: 60, Loss: 0.6837\n",
      "Epoch: 1, Batch: 61, Loss: 0.6687\n",
      "Epoch: 1, Batch: 62, Loss: 0.6987\n",
      "Epoch: 1, Batch: 63, Loss: 0.6478\n",
      "Epoch: 1, Batch: 64, Loss: 0.7049\n",
      "Epoch: 1, Batch: 65, Loss: 0.6718\n",
      "Epoch: 1, Batch: 66, Loss: 0.6949\n",
      "Epoch: 1, Batch: 67, Loss: 0.7221\n",
      "Epoch: 1, Batch: 68, Loss: 0.7172\n",
      "Epoch: 1, Batch: 69, Loss: 0.7012\n",
      "Epoch: 1, Batch: 70, Loss: 0.6848\n",
      "Epoch: 1, Batch: 71, Loss: 0.6878\n",
      "Epoch: 1, Batch: 72, Loss: 0.6689\n",
      "Epoch: 1, Batch: 73, Loss: 0.6759\n",
      "Epoch: 1, Batch: 74, Loss: 0.6875\n",
      "Epoch: 1, Batch: 75, Loss: 0.6971\n",
      "Epoch: 1, Batch: 76, Loss: 0.6776\n",
      "Epoch: 1, Batch: 77, Loss: 0.6937\n",
      "Epoch: 1, Batch: 78, Loss: 0.6940\n",
      "Epoch: 1, Batch: 79, Loss: 0.6659\n",
      "Epoch: 1, Batch: 80, Loss: 0.6558\n",
      "Epoch: 1, Batch: 81, Loss: 0.6912\n",
      "Epoch: 1, Batch: 82, Loss: 0.6510\n",
      "Epoch: 1, Batch: 83, Loss: 0.7276\n",
      "Epoch: 1, Batch: 84, Loss: 0.6932\n",
      "Epoch: 1, Batch: 85, Loss: 0.6967\n",
      "Epoch: 1, Batch: 86, Loss: 0.6581\n",
      "Epoch: 1, Batch: 87, Loss: 0.6306\n",
      "Epoch: 1, Batch: 88, Loss: 0.6685\n",
      "Epoch: 1, Batch: 89, Loss: 0.6746\n",
      "Epoch: 1, Batch: 90, Loss: 0.7617\n",
      "Epoch: 1, Batch: 91, Loss: 0.6745\n",
      "Epoch: 1, Batch: 92, Loss: 0.6221\n",
      "Epoch: 1, Batch: 93, Loss: 0.6771\n",
      "Epoch: 1, Batch: 94, Loss: 0.6676\n",
      "Epoch: 1, Batch: 95, Loss: 0.7209\n",
      "Epoch: 1, Batch: 96, Loss: 0.7365\n",
      "Epoch: 1, Batch: 97, Loss: 0.6516\n",
      "Epoch: 1, Batch: 98, Loss: 0.7029\n",
      "Epoch: 1, Batch: 99, Loss: 0.6185\n",
      "Epoch: 1, Batch: 100, Loss: 0.7267\n",
      "Epoch: 1, Batch: 101, Loss: 0.7083\n",
      "Epoch: 1, Batch: 102, Loss: 0.7054\n",
      "Epoch: 1, Batch: 103, Loss: 0.7381\n",
      "Epoch: 1, Batch: 104, Loss: 0.7286\n",
      "Epoch: 1, Batch: 105, Loss: 0.7750\n",
      "Epoch: 1, Batch: 106, Loss: 0.6445\n",
      "Epoch: 1, Batch: 107, Loss: 0.7094\n",
      "Epoch: 1, Batch: 108, Loss: 0.7242\n",
      "Epoch: 1, Batch: 109, Loss: 0.6986\n",
      "Epoch: 1, Batch: 110, Loss: 0.7081\n",
      "Epoch: 1, Batch: 111, Loss: 0.6840\n",
      "Epoch: 1, Batch: 112, Loss: 0.6852\n",
      "Epoch: 2, Batch: 0, Loss: 0.6665\n",
      "Epoch: 2, Batch: 1, Loss: 0.6730\n",
      "Epoch: 2, Batch: 2, Loss: 0.6480\n",
      "Epoch: 2, Batch: 3, Loss: 0.6675\n",
      "Epoch: 2, Batch: 4, Loss: 0.6282\n",
      "Epoch: 2, Batch: 5, Loss: 0.6446\n",
      "Epoch: 2, Batch: 6, Loss: 0.6982\n",
      "Epoch: 2, Batch: 7, Loss: 0.6644\n",
      "Epoch: 2, Batch: 8, Loss: 0.6456\n",
      "Epoch: 2, Batch: 9, Loss: 0.6461\n",
      "Epoch: 2, Batch: 10, Loss: 0.6848\n",
      "Epoch: 2, Batch: 11, Loss: 0.6192\n",
      "Epoch: 2, Batch: 12, Loss: 0.6339\n",
      "Epoch: 2, Batch: 13, Loss: 0.6836\n",
      "Epoch: 2, Batch: 14, Loss: 0.6389\n",
      "Epoch: 2, Batch: 15, Loss: 0.5998\n",
      "Epoch: 2, Batch: 16, Loss: 0.7483\n",
      "Epoch: 2, Batch: 17, Loss: 0.7145\n",
      "Epoch: 2, Batch: 18, Loss: 0.7242\n",
      "Epoch: 2, Batch: 19, Loss: 0.6741\n",
      "Epoch: 2, Batch: 20, Loss: 0.7811\n",
      "Epoch: 2, Batch: 21, Loss: 0.5935\n",
      "Epoch: 2, Batch: 22, Loss: 0.6938\n",
      "Epoch: 2, Batch: 23, Loss: 0.7310\n",
      "Epoch: 2, Batch: 24, Loss: 0.6751\n",
      "Epoch: 2, Batch: 25, Loss: 0.6822\n",
      "Epoch: 2, Batch: 26, Loss: 0.6297\n",
      "Epoch: 2, Batch: 27, Loss: 0.7267\n",
      "Epoch: 2, Batch: 28, Loss: 0.6781\n",
      "Epoch: 2, Batch: 29, Loss: 0.6814\n",
      "Epoch: 2, Batch: 30, Loss: 0.6307\n",
      "Epoch: 2, Batch: 31, Loss: 0.6606\n",
      "Epoch: 2, Batch: 32, Loss: 0.7152\n",
      "Epoch: 2, Batch: 33, Loss: 0.7361\n",
      "Epoch: 2, Batch: 34, Loss: 0.6574\n",
      "Epoch: 2, Batch: 35, Loss: 0.6853\n",
      "Epoch: 2, Batch: 36, Loss: 0.7100\n",
      "Epoch: 2, Batch: 37, Loss: 0.6917\n",
      "Epoch: 2, Batch: 38, Loss: 0.6417\n",
      "Epoch: 2, Batch: 39, Loss: 0.6498\n",
      "Epoch: 2, Batch: 40, Loss: 0.6890\n",
      "Epoch: 2, Batch: 41, Loss: 0.6594\n",
      "Epoch: 2, Batch: 42, Loss: 0.7055\n",
      "Epoch: 2, Batch: 43, Loss: 0.6831\n",
      "Epoch: 2, Batch: 44, Loss: 0.7017\n",
      "Epoch: 2, Batch: 45, Loss: 0.6236\n",
      "Epoch: 2, Batch: 46, Loss: 0.7141\n",
      "Epoch: 2, Batch: 47, Loss: 0.6545\n",
      "Epoch: 2, Batch: 48, Loss: 0.7170\n",
      "Epoch: 2, Batch: 49, Loss: 0.6472\n",
      "Epoch: 2, Batch: 50, Loss: 0.6979\n",
      "Epoch: 2, Batch: 51, Loss: 0.6479\n",
      "Epoch: 2, Batch: 52, Loss: 0.6376\n",
      "Epoch: 2, Batch: 53, Loss: 0.6619\n",
      "Epoch: 2, Batch: 54, Loss: 0.7247\n",
      "Epoch: 2, Batch: 55, Loss: 0.6374\n",
      "Epoch: 2, Batch: 56, Loss: 0.7044\n",
      "Epoch: 2, Batch: 57, Loss: 0.7136\n",
      "Epoch: 2, Batch: 58, Loss: 0.6488\n",
      "Epoch: 2, Batch: 59, Loss: 0.6695\n",
      "Epoch: 2, Batch: 60, Loss: 0.6698\n",
      "Epoch: 2, Batch: 61, Loss: 0.6777\n",
      "Epoch: 2, Batch: 62, Loss: 0.6969\n",
      "Epoch: 2, Batch: 63, Loss: 0.6298\n",
      "Epoch: 2, Batch: 64, Loss: 0.7065\n",
      "Epoch: 2, Batch: 65, Loss: 0.6838\n",
      "Epoch: 2, Batch: 66, Loss: 0.6937\n",
      "Epoch: 2, Batch: 67, Loss: 0.7351\n",
      "Epoch: 2, Batch: 68, Loss: 0.6980\n",
      "Epoch: 2, Batch: 69, Loss: 0.7070\n",
      "Epoch: 2, Batch: 70, Loss: 0.6453\n",
      "Epoch: 2, Batch: 71, Loss: 0.6919\n",
      "Epoch: 2, Batch: 72, Loss: 0.6600\n",
      "Epoch: 2, Batch: 73, Loss: 0.6685\n",
      "Epoch: 2, Batch: 74, Loss: 0.6722\n",
      "Epoch: 2, Batch: 75, Loss: 0.6829\n",
      "Epoch: 2, Batch: 76, Loss: 0.6713\n",
      "Epoch: 2, Batch: 77, Loss: 0.7057\n",
      "Epoch: 2, Batch: 78, Loss: 0.6793\n",
      "Epoch: 2, Batch: 79, Loss: 0.6299\n",
      "Epoch: 2, Batch: 80, Loss: 0.6295\n",
      "Epoch: 2, Batch: 81, Loss: 0.6810\n",
      "Epoch: 2, Batch: 82, Loss: 0.6368\n",
      "Epoch: 2, Batch: 83, Loss: 0.7060\n",
      "Epoch: 2, Batch: 84, Loss: 0.6615\n",
      "Epoch: 2, Batch: 85, Loss: 0.6892\n",
      "Epoch: 2, Batch: 86, Loss: 0.6491\n",
      "Epoch: 2, Batch: 87, Loss: 0.6251\n",
      "Epoch: 2, Batch: 88, Loss: 0.6424\n",
      "Epoch: 2, Batch: 89, Loss: 0.6797\n",
      "Epoch: 2, Batch: 90, Loss: 0.7852\n",
      "Epoch: 2, Batch: 91, Loss: 0.6376\n",
      "Epoch: 2, Batch: 92, Loss: 0.5951\n",
      "Epoch: 2, Batch: 93, Loss: 0.6463\n",
      "Epoch: 2, Batch: 94, Loss: 0.6574\n",
      "Epoch: 2, Batch: 95, Loss: 0.7398\n",
      "Epoch: 2, Batch: 96, Loss: 0.7342\n",
      "Epoch: 2, Batch: 97, Loss: 0.6369\n",
      "Epoch: 2, Batch: 98, Loss: 0.7172\n",
      "Epoch: 2, Batch: 99, Loss: 0.5930\n",
      "Epoch: 2, Batch: 100, Loss: 0.7296\n",
      "Epoch: 2, Batch: 101, Loss: 0.7290\n",
      "Epoch: 2, Batch: 102, Loss: 0.7565\n",
      "Epoch: 2, Batch: 103, Loss: 0.7552\n",
      "Epoch: 2, Batch: 104, Loss: 0.7225\n",
      "Epoch: 2, Batch: 105, Loss: 0.7618\n",
      "Epoch: 2, Batch: 106, Loss: 0.6445\n",
      "Epoch: 2, Batch: 107, Loss: 0.7031\n",
      "Epoch: 2, Batch: 108, Loss: 0.7053\n",
      "Epoch: 2, Batch: 109, Loss: 0.6746\n",
      "Epoch: 2, Batch: 110, Loss: 0.6910\n",
      "Epoch: 2, Batch: 111, Loss: 0.6668\n",
      "Epoch: 2, Batch: 112, Loss: 0.6455\n",
      "Epoch: 3, Batch: 0, Loss: 0.6389\n",
      "Epoch: 3, Batch: 1, Loss: 0.6602\n",
      "Epoch: 3, Batch: 2, Loss: 0.6157\n",
      "Epoch: 3, Batch: 3, Loss: 0.6685\n",
      "Epoch: 3, Batch: 4, Loss: 0.6182\n",
      "Epoch: 3, Batch: 5, Loss: 0.6475\n",
      "Epoch: 3, Batch: 6, Loss: 0.6916\n",
      "Epoch: 3, Batch: 7, Loss: 0.7060\n",
      "Epoch: 3, Batch: 8, Loss: 0.6266\n",
      "Epoch: 3, Batch: 9, Loss: 0.6616\n",
      "Epoch: 3, Batch: 10, Loss: 0.6804\n",
      "Epoch: 3, Batch: 11, Loss: 0.5875\n",
      "Epoch: 3, Batch: 12, Loss: 0.6203\n",
      "Epoch: 3, Batch: 13, Loss: 0.6891\n",
      "Epoch: 3, Batch: 14, Loss: 0.6372\n",
      "Epoch: 3, Batch: 15, Loss: 0.5718\n",
      "Epoch: 3, Batch: 16, Loss: 0.7630\n",
      "Epoch: 3, Batch: 17, Loss: 0.7403\n",
      "Epoch: 3, Batch: 18, Loss: 0.7257\n",
      "Epoch: 3, Batch: 19, Loss: 0.6604\n",
      "Epoch: 3, Batch: 20, Loss: 0.8285\n",
      "Epoch: 3, Batch: 21, Loss: 0.5825\n",
      "Epoch: 3, Batch: 22, Loss: 0.6762\n",
      "Epoch: 3, Batch: 23, Loss: 0.7033\n",
      "Epoch: 3, Batch: 24, Loss: 0.6786\n",
      "Epoch: 3, Batch: 25, Loss: 0.6776\n",
      "Epoch: 3, Batch: 26, Loss: 0.6359\n",
      "Epoch: 3, Batch: 27, Loss: 0.7119\n",
      "Epoch: 3, Batch: 28, Loss: 0.6665\n",
      "Epoch: 3, Batch: 29, Loss: 0.6811\n",
      "Epoch: 3, Batch: 30, Loss: 0.6017\n",
      "Epoch: 3, Batch: 31, Loss: 0.6606\n",
      "Epoch: 3, Batch: 32, Loss: 0.7007\n",
      "Epoch: 3, Batch: 33, Loss: 0.7071\n",
      "Epoch: 3, Batch: 34, Loss: 0.6473\n",
      "Epoch: 3, Batch: 35, Loss: 0.6667\n",
      "Epoch: 3, Batch: 36, Loss: 0.6723\n",
      "Epoch: 3, Batch: 37, Loss: 0.6853\n",
      "Epoch: 3, Batch: 38, Loss: 0.6402\n",
      "Epoch: 3, Batch: 39, Loss: 0.6315\n",
      "Epoch: 3, Batch: 40, Loss: 0.6530\n",
      "Epoch: 3, Batch: 41, Loss: 0.6811\n",
      "Epoch: 3, Batch: 42, Loss: 0.6725\n",
      "Epoch: 3, Batch: 43, Loss: 0.6941\n",
      "Epoch: 3, Batch: 44, Loss: 0.6983\n",
      "Epoch: 3, Batch: 45, Loss: 0.6013\n",
      "Epoch: 3, Batch: 46, Loss: 0.6983\n",
      "Epoch: 3, Batch: 47, Loss: 0.6453\n",
      "Epoch: 3, Batch: 48, Loss: 0.7312\n",
      "Epoch: 3, Batch: 49, Loss: 0.6486\n",
      "Epoch: 3, Batch: 50, Loss: 0.6804\n",
      "Epoch: 3, Batch: 51, Loss: 0.6334\n",
      "Epoch: 3, Batch: 52, Loss: 0.6171\n",
      "Epoch: 3, Batch: 53, Loss: 0.6560\n",
      "Epoch: 3, Batch: 54, Loss: 0.7136\n",
      "Epoch: 3, Batch: 55, Loss: 0.6252\n",
      "Epoch: 3, Batch: 56, Loss: 0.6791\n",
      "Epoch: 3, Batch: 57, Loss: 0.7207\n",
      "Epoch: 3, Batch: 58, Loss: 0.6495\n",
      "Epoch: 3, Batch: 59, Loss: 0.6223\n",
      "Epoch: 3, Batch: 60, Loss: 0.6475\n",
      "Epoch: 3, Batch: 61, Loss: 0.6592\n",
      "Epoch: 3, Batch: 62, Loss: 0.7122\n",
      "Epoch: 3, Batch: 63, Loss: 0.6144\n",
      "Epoch: 3, Batch: 64, Loss: 0.6960\n",
      "Epoch: 3, Batch: 65, Loss: 0.6761\n",
      "Epoch: 3, Batch: 66, Loss: 0.6799\n",
      "Epoch: 3, Batch: 67, Loss: 0.7186\n",
      "Epoch: 3, Batch: 68, Loss: 0.6977\n",
      "Epoch: 3, Batch: 69, Loss: 0.6851\n",
      "Epoch: 3, Batch: 70, Loss: 0.6141\n",
      "Epoch: 3, Batch: 71, Loss: 0.6442\n",
      "Epoch: 3, Batch: 72, Loss: 0.6562\n",
      "Epoch: 3, Batch: 73, Loss: 0.6606\n",
      "Epoch: 3, Batch: 74, Loss: 0.6480\n",
      "Epoch: 3, Batch: 75, Loss: 0.6722\n",
      "Epoch: 3, Batch: 76, Loss: 0.6230\n",
      "Epoch: 3, Batch: 77, Loss: 0.6967\n",
      "Epoch: 3, Batch: 78, Loss: 0.7013\n",
      "Epoch: 3, Batch: 79, Loss: 0.6258\n",
      "Epoch: 3, Batch: 80, Loss: 0.5649\n",
      "Epoch: 3, Batch: 81, Loss: 0.6606\n",
      "Epoch: 3, Batch: 82, Loss: 0.6101\n",
      "Epoch: 3, Batch: 83, Loss: 0.7129\n",
      "Epoch: 3, Batch: 84, Loss: 0.6315\n",
      "Epoch: 3, Batch: 85, Loss: 0.7160\n",
      "Epoch: 3, Batch: 86, Loss: 0.6258\n",
      "Epoch: 3, Batch: 87, Loss: 0.5741\n",
      "Epoch: 3, Batch: 88, Loss: 0.6238\n",
      "Epoch: 3, Batch: 89, Loss: 0.6426\n",
      "Epoch: 3, Batch: 90, Loss: 0.7983\n",
      "Epoch: 3, Batch: 91, Loss: 0.6487\n",
      "Epoch: 3, Batch: 92, Loss: 0.5694\n",
      "Epoch: 3, Batch: 93, Loss: 0.5965\n",
      "Epoch: 3, Batch: 94, Loss: 0.6554\n",
      "Epoch: 3, Batch: 95, Loss: 0.7341\n",
      "Epoch: 3, Batch: 96, Loss: 0.7583\n",
      "Epoch: 3, Batch: 97, Loss: 0.6151\n",
      "Epoch: 3, Batch: 98, Loss: 0.6919\n",
      "Epoch: 3, Batch: 99, Loss: 0.5748\n",
      "Epoch: 3, Batch: 100, Loss: 0.7328\n",
      "Epoch: 3, Batch: 101, Loss: 0.7619\n",
      "Epoch: 3, Batch: 102, Loss: 0.8148\n",
      "Epoch: 3, Batch: 103, Loss: 0.7285\n",
      "Epoch: 3, Batch: 104, Loss: 0.6800\n",
      "Epoch: 3, Batch: 105, Loss: 0.7273\n",
      "Epoch: 3, Batch: 106, Loss: 0.6073\n",
      "Epoch: 3, Batch: 107, Loss: 0.6304\n",
      "Epoch: 3, Batch: 108, Loss: 0.7094\n",
      "Epoch: 3, Batch: 109, Loss: 0.6560\n",
      "Epoch: 3, Batch: 110, Loss: 0.6529\n",
      "Epoch: 3, Batch: 111, Loss: 0.6671\n",
      "Epoch: 3, Batch: 112, Loss: 0.6120\n",
      "Epoch: 4, Batch: 0, Loss: 0.6379\n",
      "Epoch: 4, Batch: 1, Loss: 0.6493\n",
      "Epoch: 4, Batch: 2, Loss: 0.5856\n",
      "Epoch: 4, Batch: 3, Loss: 0.7015\n",
      "Epoch: 4, Batch: 4, Loss: 0.6268\n",
      "Epoch: 4, Batch: 5, Loss: 0.6094\n",
      "Epoch: 4, Batch: 6, Loss: 0.6638\n",
      "Epoch: 4, Batch: 7, Loss: 0.7370\n",
      "Epoch: 4, Batch: 8, Loss: 0.6013\n",
      "Epoch: 4, Batch: 9, Loss: 0.6440\n",
      "Epoch: 4, Batch: 10, Loss: 0.6895\n",
      "Epoch: 4, Batch: 11, Loss: 0.5387\n",
      "Epoch: 4, Batch: 12, Loss: 0.5824\n",
      "Epoch: 4, Batch: 13, Loss: 0.6729\n",
      "Epoch: 4, Batch: 14, Loss: 0.5635\n",
      "Epoch: 4, Batch: 15, Loss: 0.5216\n",
      "Epoch: 4, Batch: 16, Loss: 0.7929\n",
      "Epoch: 4, Batch: 17, Loss: 0.7362\n",
      "Epoch: 4, Batch: 18, Loss: 0.7302\n",
      "Epoch: 4, Batch: 19, Loss: 0.6581\n",
      "Epoch: 4, Batch: 20, Loss: 0.8373\n",
      "Epoch: 4, Batch: 21, Loss: 0.5479\n",
      "Epoch: 4, Batch: 22, Loss: 0.6761\n",
      "Epoch: 4, Batch: 23, Loss: 0.7131\n",
      "Epoch: 4, Batch: 24, Loss: 0.6678\n",
      "Epoch: 4, Batch: 25, Loss: 0.6814\n",
      "Epoch: 4, Batch: 26, Loss: 0.6317\n",
      "Epoch: 4, Batch: 27, Loss: 0.7522\n",
      "Epoch: 4, Batch: 28, Loss: 0.6451\n",
      "Epoch: 4, Batch: 29, Loss: 0.6706\n",
      "Epoch: 4, Batch: 30, Loss: 0.5881\n",
      "Epoch: 4, Batch: 31, Loss: 0.6503\n",
      "Epoch: 4, Batch: 32, Loss: 0.6774\n",
      "Epoch: 4, Batch: 33, Loss: 0.6755\n",
      "Epoch: 4, Batch: 34, Loss: 0.6278\n",
      "Epoch: 4, Batch: 35, Loss: 0.7253\n",
      "Epoch: 4, Batch: 36, Loss: 0.6125\n",
      "Epoch: 4, Batch: 37, Loss: 0.6688\n",
      "Epoch: 4, Batch: 38, Loss: 0.6514\n",
      "Epoch: 4, Batch: 39, Loss: 0.6682\n",
      "Epoch: 4, Batch: 40, Loss: 0.5869\n",
      "Epoch: 4, Batch: 41, Loss: 0.6525\n",
      "Epoch: 4, Batch: 42, Loss: 0.6704\n",
      "Epoch: 4, Batch: 43, Loss: 0.7074\n",
      "Epoch: 4, Batch: 44, Loss: 0.6890\n",
      "Epoch: 4, Batch: 45, Loss: 0.5838\n",
      "Epoch: 4, Batch: 46, Loss: 0.7269\n",
      "Epoch: 4, Batch: 47, Loss: 0.6259\n",
      "Epoch: 4, Batch: 48, Loss: 0.7211\n",
      "Epoch: 4, Batch: 49, Loss: 0.6329\n",
      "Epoch: 4, Batch: 50, Loss: 0.6543\n",
      "Epoch: 4, Batch: 51, Loss: 0.6185\n",
      "Epoch: 4, Batch: 52, Loss: 0.5983\n",
      "Epoch: 4, Batch: 53, Loss: 0.5997\n",
      "Epoch: 4, Batch: 54, Loss: 0.6913\n",
      "Epoch: 4, Batch: 55, Loss: 0.6066\n",
      "Epoch: 4, Batch: 56, Loss: 0.6620\n",
      "Epoch: 4, Batch: 57, Loss: 0.7488\n",
      "Epoch: 4, Batch: 58, Loss: 0.6018\n",
      "Epoch: 4, Batch: 59, Loss: 0.5981\n",
      "Epoch: 4, Batch: 60, Loss: 0.6301\n",
      "Epoch: 4, Batch: 61, Loss: 0.6581\n",
      "Epoch: 4, Batch: 62, Loss: 0.6973\n",
      "Epoch: 4, Batch: 63, Loss: 0.6020\n",
      "Epoch: 4, Batch: 64, Loss: 0.6621\n",
      "Epoch: 4, Batch: 65, Loss: 0.6571\n",
      "Epoch: 4, Batch: 66, Loss: 0.6788\n",
      "Epoch: 4, Batch: 67, Loss: 0.7037\n",
      "Epoch: 4, Batch: 68, Loss: 0.7224\n",
      "Epoch: 4, Batch: 69, Loss: 0.6596\n",
      "Epoch: 4, Batch: 70, Loss: 0.5836\n",
      "Epoch: 4, Batch: 71, Loss: 0.6523\n",
      "Epoch: 4, Batch: 72, Loss: 0.6407\n",
      "Epoch: 4, Batch: 73, Loss: 0.6318\n",
      "Epoch: 4, Batch: 74, Loss: 0.6853\n",
      "Epoch: 4, Batch: 75, Loss: 0.6500\n",
      "Epoch: 4, Batch: 76, Loss: 0.6351\n",
      "Epoch: 4, Batch: 77, Loss: 0.6760\n",
      "Epoch: 4, Batch: 78, Loss: 0.6624\n",
      "Epoch: 4, Batch: 79, Loss: 0.5639\n",
      "Epoch: 4, Batch: 80, Loss: 0.5174\n",
      "Epoch: 4, Batch: 81, Loss: 0.6617\n",
      "Epoch: 4, Batch: 82, Loss: 0.5820\n",
      "Epoch: 4, Batch: 83, Loss: 0.6803\n",
      "Epoch: 4, Batch: 84, Loss: 0.6466\n",
      "Epoch: 4, Batch: 85, Loss: 0.6886\n",
      "Epoch: 4, Batch: 86, Loss: 0.5723\n",
      "Epoch: 4, Batch: 87, Loss: 0.5392\n",
      "Epoch: 4, Batch: 88, Loss: 0.5911\n",
      "Epoch: 4, Batch: 89, Loss: 0.6006\n",
      "Epoch: 4, Batch: 90, Loss: 0.8259\n",
      "Epoch: 4, Batch: 91, Loss: 0.6018\n",
      "Epoch: 4, Batch: 92, Loss: 0.5354\n",
      "Epoch: 4, Batch: 93, Loss: 0.5862\n",
      "Epoch: 4, Batch: 94, Loss: 0.6448\n",
      "Epoch: 4, Batch: 95, Loss: 0.7795\n",
      "Epoch: 4, Batch: 96, Loss: 0.7739\n",
      "Epoch: 4, Batch: 97, Loss: 0.6000\n",
      "Epoch: 4, Batch: 98, Loss: 0.7253\n",
      "Epoch: 4, Batch: 99, Loss: 0.5570\n",
      "Epoch: 4, Batch: 100, Loss: 0.7650\n",
      "Epoch: 4, Batch: 101, Loss: 0.7388\n",
      "Epoch: 4, Batch: 102, Loss: 0.8057\n",
      "Epoch: 4, Batch: 103, Loss: 0.7121\n",
      "Epoch: 4, Batch: 104, Loss: 0.6381\n",
      "Epoch: 4, Batch: 105, Loss: 0.7544\n",
      "Epoch: 4, Batch: 106, Loss: 0.5805\n",
      "Epoch: 4, Batch: 107, Loss: 0.6147\n",
      "Epoch: 4, Batch: 108, Loss: 0.6885\n",
      "Epoch: 4, Batch: 109, Loss: 0.6453\n",
      "Epoch: 4, Batch: 110, Loss: 0.6252\n",
      "Epoch: 4, Batch: 111, Loss: 0.6483\n",
      "Epoch: 4, Batch: 112, Loss: 0.5063\n",
      "Epoch: 5, Batch: 0, Loss: 0.6504\n",
      "Epoch: 5, Batch: 1, Loss: 0.6682\n",
      "Epoch: 5, Batch: 2, Loss: 0.5489\n",
      "Epoch: 5, Batch: 3, Loss: 0.6507\n",
      "Epoch: 5, Batch: 4, Loss: 0.5935\n",
      "Epoch: 5, Batch: 5, Loss: 0.6091\n",
      "Epoch: 5, Batch: 6, Loss: 0.6850\n",
      "Epoch: 5, Batch: 7, Loss: 0.7355\n",
      "Epoch: 5, Batch: 8, Loss: 0.5605\n",
      "Epoch: 5, Batch: 9, Loss: 0.6093\n",
      "Epoch: 5, Batch: 10, Loss: 0.6670\n",
      "Epoch: 5, Batch: 11, Loss: 0.4911\n",
      "Epoch: 5, Batch: 12, Loss: 0.5562\n",
      "Epoch: 5, Batch: 13, Loss: 0.6757\n",
      "Epoch: 5, Batch: 14, Loss: 0.5769\n",
      "Epoch: 5, Batch: 15, Loss: 0.4813\n",
      "Epoch: 5, Batch: 16, Loss: 0.8314\n",
      "Epoch: 5, Batch: 17, Loss: 0.7723\n",
      "Epoch: 5, Batch: 18, Loss: 0.7446\n",
      "Epoch: 5, Batch: 19, Loss: 0.6596\n",
      "Epoch: 5, Batch: 20, Loss: 0.8966\n",
      "Epoch: 5, Batch: 21, Loss: 0.5491\n",
      "Epoch: 5, Batch: 22, Loss: 0.6641\n",
      "Epoch: 5, Batch: 23, Loss: 0.6675\n",
      "Epoch: 5, Batch: 24, Loss: 0.6113\n",
      "Epoch: 5, Batch: 25, Loss: 0.6645\n",
      "Epoch: 5, Batch: 26, Loss: 0.6255\n",
      "Epoch: 5, Batch: 27, Loss: 0.6942\n",
      "Epoch: 5, Batch: 28, Loss: 0.6171\n",
      "Epoch: 5, Batch: 29, Loss: 0.6257\n",
      "Epoch: 5, Batch: 30, Loss: 0.5631\n",
      "Epoch: 5, Batch: 31, Loss: 0.6392\n",
      "Epoch: 5, Batch: 32, Loss: 0.6431\n",
      "Epoch: 5, Batch: 33, Loss: 0.6250\n",
      "Epoch: 5, Batch: 34, Loss: 0.6206\n",
      "Epoch: 5, Batch: 35, Loss: 0.7058\n",
      "Epoch: 5, Batch: 36, Loss: 0.5353\n",
      "Epoch: 5, Batch: 37, Loss: 0.6420\n",
      "Epoch: 5, Batch: 38, Loss: 0.6755\n",
      "Epoch: 5, Batch: 39, Loss: 0.6190\n",
      "Epoch: 5, Batch: 40, Loss: 0.5532\n",
      "Epoch: 5, Batch: 41, Loss: 0.6657\n",
      "Epoch: 5, Batch: 42, Loss: 0.6760\n",
      "Epoch: 5, Batch: 43, Loss: 0.7260\n",
      "Epoch: 5, Batch: 44, Loss: 0.6926\n",
      "Epoch: 5, Batch: 45, Loss: 0.5463\n",
      "Epoch: 5, Batch: 46, Loss: 0.7475\n",
      "Epoch: 5, Batch: 47, Loss: 0.6370\n",
      "Epoch: 5, Batch: 48, Loss: 0.7246\n",
      "Epoch: 5, Batch: 49, Loss: 0.6371\n",
      "Epoch: 5, Batch: 50, Loss: 0.6495\n",
      "Epoch: 5, Batch: 51, Loss: 0.5863\n",
      "Epoch: 5, Batch: 52, Loss: 0.6309\n",
      "Epoch: 5, Batch: 53, Loss: 0.5910\n",
      "Epoch: 5, Batch: 54, Loss: 0.7018\n",
      "Epoch: 5, Batch: 55, Loss: 0.5889\n",
      "Epoch: 5, Batch: 56, Loss: 0.6124\n",
      "Epoch: 5, Batch: 57, Loss: 0.7435\n",
      "Epoch: 5, Batch: 58, Loss: 0.5649\n",
      "Epoch: 5, Batch: 59, Loss: 0.5851\n",
      "Epoch: 5, Batch: 60, Loss: 0.6300\n",
      "Epoch: 5, Batch: 61, Loss: 0.6561\n",
      "Epoch: 5, Batch: 62, Loss: 0.7057\n",
      "Epoch: 5, Batch: 63, Loss: 0.5788\n",
      "Epoch: 5, Batch: 64, Loss: 0.6503\n",
      "Epoch: 5, Batch: 65, Loss: 0.6466\n",
      "Epoch: 5, Batch: 66, Loss: 0.6533\n",
      "Epoch: 5, Batch: 67, Loss: 0.7299\n",
      "Epoch: 5, Batch: 68, Loss: 0.6852\n",
      "Epoch: 5, Batch: 69, Loss: 0.6726\n",
      "Epoch: 5, Batch: 70, Loss: 0.5533\n",
      "Epoch: 5, Batch: 71, Loss: 0.6169\n",
      "Epoch: 5, Batch: 72, Loss: 0.6070\n",
      "Epoch: 5, Batch: 73, Loss: 0.6174\n",
      "Epoch: 5, Batch: 74, Loss: 0.6856\n",
      "Epoch: 5, Batch: 75, Loss: 0.6539\n",
      "Epoch: 5, Batch: 76, Loss: 0.5759\n",
      "Epoch: 5, Batch: 77, Loss: 0.6874\n",
      "Epoch: 5, Batch: 78, Loss: 0.6535\n",
      "Epoch: 5, Batch: 79, Loss: 0.5517\n",
      "Epoch: 5, Batch: 80, Loss: 0.5008\n",
      "Epoch: 5, Batch: 81, Loss: 0.6452\n",
      "Epoch: 5, Batch: 82, Loss: 0.5403\n",
      "Epoch: 5, Batch: 83, Loss: 0.6898\n",
      "Epoch: 5, Batch: 84, Loss: 0.6281\n",
      "Epoch: 5, Batch: 85, Loss: 0.6722\n",
      "Epoch: 5, Batch: 86, Loss: 0.5920\n",
      "Epoch: 5, Batch: 87, Loss: 0.5451\n",
      "Epoch: 5, Batch: 88, Loss: 0.5912\n",
      "Epoch: 5, Batch: 89, Loss: 0.5975\n",
      "Epoch: 5, Batch: 90, Loss: 0.7650\n",
      "Epoch: 5, Batch: 91, Loss: 0.5870\n",
      "Epoch: 5, Batch: 92, Loss: 0.5055\n",
      "Epoch: 5, Batch: 93, Loss: 0.5277\n",
      "Epoch: 5, Batch: 94, Loss: 0.6384\n",
      "Epoch: 5, Batch: 95, Loss: 0.7142\n",
      "Epoch: 5, Batch: 96, Loss: 0.7573\n",
      "Epoch: 5, Batch: 97, Loss: 0.5757\n",
      "Epoch: 5, Batch: 98, Loss: 0.6870\n",
      "Epoch: 5, Batch: 99, Loss: 0.5394\n",
      "Epoch: 5, Batch: 100, Loss: 0.7848\n",
      "Epoch: 5, Batch: 101, Loss: 0.7184\n",
      "Epoch: 5, Batch: 102, Loss: 0.7759\n",
      "Epoch: 5, Batch: 103, Loss: 0.6879\n",
      "Epoch: 5, Batch: 104, Loss: 0.6263\n",
      "Epoch: 5, Batch: 105, Loss: 0.7236\n",
      "Epoch: 5, Batch: 106, Loss: 0.5224\n",
      "Epoch: 5, Batch: 107, Loss: 0.6037\n",
      "Epoch: 5, Batch: 108, Loss: 0.6728\n",
      "Epoch: 5, Batch: 109, Loss: 0.6078\n",
      "Epoch: 5, Batch: 110, Loss: 0.5873\n",
      "Epoch: 5, Batch: 111, Loss: 0.6129\n",
      "Epoch: 5, Batch: 112, Loss: 0.4548\n",
      "Epoch: 6, Batch: 0, Loss: 0.6720\n",
      "Epoch: 6, Batch: 1, Loss: 0.6683\n",
      "Epoch: 6, Batch: 2, Loss: 0.5474\n",
      "Epoch: 6, Batch: 3, Loss: 0.6762\n",
      "Epoch: 6, Batch: 4, Loss: 0.5853\n",
      "Epoch: 6, Batch: 5, Loss: 0.5900\n",
      "Epoch: 6, Batch: 6, Loss: 0.6755\n",
      "Epoch: 6, Batch: 7, Loss: 0.7755\n",
      "Epoch: 6, Batch: 8, Loss: 0.5162\n",
      "Epoch: 6, Batch: 9, Loss: 0.6373\n",
      "Epoch: 6, Batch: 10, Loss: 0.6427\n",
      "Epoch: 6, Batch: 11, Loss: 0.4737\n",
      "Epoch: 6, Batch: 12, Loss: 0.5021\n",
      "Epoch: 6, Batch: 13, Loss: 0.6387\n",
      "Epoch: 6, Batch: 14, Loss: 0.4900\n",
      "Epoch: 6, Batch: 15, Loss: 0.4609\n",
      "Epoch: 6, Batch: 16, Loss: 0.8321\n",
      "Epoch: 6, Batch: 17, Loss: 0.7554\n",
      "Epoch: 6, Batch: 18, Loss: 0.7322\n",
      "Epoch: 6, Batch: 19, Loss: 0.6981\n",
      "Epoch: 6, Batch: 20, Loss: 0.9307\n",
      "Epoch: 6, Batch: 21, Loss: 0.5276\n",
      "Epoch: 6, Batch: 22, Loss: 0.6558\n",
      "Epoch: 6, Batch: 23, Loss: 0.6241\n",
      "Epoch: 6, Batch: 24, Loss: 0.5696\n",
      "Epoch: 6, Batch: 25, Loss: 0.6988\n",
      "Epoch: 6, Batch: 26, Loss: 0.6510\n",
      "Epoch: 6, Batch: 27, Loss: 0.6792\n",
      "Epoch: 6, Batch: 28, Loss: 0.6282\n",
      "Epoch: 6, Batch: 29, Loss: 0.6176\n",
      "Epoch: 6, Batch: 30, Loss: 0.5856\n",
      "Epoch: 6, Batch: 31, Loss: 0.6373\n",
      "Epoch: 6, Batch: 32, Loss: 0.6402\n",
      "Epoch: 6, Batch: 33, Loss: 0.6041\n",
      "Epoch: 6, Batch: 34, Loss: 0.6387\n",
      "Epoch: 6, Batch: 35, Loss: 0.7114\n",
      "Epoch: 6, Batch: 36, Loss: 0.5481\n",
      "Epoch: 6, Batch: 37, Loss: 0.6471\n",
      "Epoch: 6, Batch: 38, Loss: 0.6878\n",
      "Epoch: 6, Batch: 39, Loss: 0.6131\n",
      "Epoch: 6, Batch: 40, Loss: 0.4857\n",
      "Epoch: 6, Batch: 41, Loss: 0.6433\n",
      "Epoch: 6, Batch: 42, Loss: 0.6914\n",
      "Epoch: 6, Batch: 43, Loss: 0.7017\n",
      "Epoch: 6, Batch: 44, Loss: 0.7204\n",
      "Epoch: 6, Batch: 45, Loss: 0.5259\n",
      "Epoch: 6, Batch: 46, Loss: 0.7449\n",
      "Epoch: 6, Batch: 47, Loss: 0.6133\n",
      "Epoch: 6, Batch: 48, Loss: 0.6988\n",
      "Epoch: 6, Batch: 49, Loss: 0.6359\n",
      "Epoch: 6, Batch: 50, Loss: 0.6385\n",
      "Epoch: 6, Batch: 51, Loss: 0.5942\n",
      "Epoch: 6, Batch: 52, Loss: 0.6387\n",
      "Epoch: 6, Batch: 53, Loss: 0.5068\n",
      "Epoch: 6, Batch: 54, Loss: 0.6810\n",
      "Epoch: 6, Batch: 55, Loss: 0.5586\n",
      "Epoch: 6, Batch: 56, Loss: 0.5947\n",
      "Epoch: 6, Batch: 57, Loss: 0.7399\n",
      "Epoch: 6, Batch: 58, Loss: 0.5706\n",
      "Epoch: 6, Batch: 59, Loss: 0.5532\n",
      "Epoch: 6, Batch: 60, Loss: 0.5841\n",
      "Epoch: 6, Batch: 61, Loss: 0.6448\n",
      "Epoch: 6, Batch: 62, Loss: 0.6813\n",
      "Epoch: 6, Batch: 63, Loss: 0.5507\n",
      "Epoch: 6, Batch: 64, Loss: 0.6287\n",
      "Epoch: 6, Batch: 65, Loss: 0.6334\n",
      "Epoch: 6, Batch: 66, Loss: 0.6461\n",
      "Epoch: 6, Batch: 67, Loss: 0.7340\n",
      "Epoch: 6, Batch: 68, Loss: 0.6665\n",
      "Epoch: 6, Batch: 69, Loss: 0.6807\n",
      "Epoch: 6, Batch: 70, Loss: 0.5060\n",
      "Epoch: 6, Batch: 71, Loss: 0.6108\n",
      "Epoch: 6, Batch: 72, Loss: 0.5882\n",
      "Epoch: 6, Batch: 73, Loss: 0.5934\n",
      "Epoch: 6, Batch: 74, Loss: 0.6552\n",
      "Epoch: 6, Batch: 75, Loss: 0.6265\n",
      "Epoch: 6, Batch: 76, Loss: 0.5813\n",
      "Epoch: 6, Batch: 77, Loss: 0.7084\n",
      "Epoch: 6, Batch: 78, Loss: 0.6003\n",
      "Epoch: 6, Batch: 79, Loss: 0.5159\n",
      "Epoch: 6, Batch: 80, Loss: 0.4469\n",
      "Epoch: 6, Batch: 81, Loss: 0.6535\n",
      "Epoch: 6, Batch: 82, Loss: 0.5092\n",
      "Epoch: 6, Batch: 83, Loss: 0.6824\n",
      "Epoch: 6, Batch: 84, Loss: 0.6113\n",
      "Epoch: 6, Batch: 85, Loss: 0.6695\n",
      "Epoch: 6, Batch: 86, Loss: 0.5927\n",
      "Epoch: 6, Batch: 87, Loss: 0.4929\n",
      "Epoch: 6, Batch: 88, Loss: 0.5591\n",
      "Epoch: 6, Batch: 89, Loss: 0.5662\n",
      "Epoch: 6, Batch: 90, Loss: 0.7227\n",
      "Epoch: 6, Batch: 91, Loss: 0.5630\n",
      "Epoch: 6, Batch: 92, Loss: 0.4829\n",
      "Epoch: 6, Batch: 93, Loss: 0.4857\n",
      "Epoch: 6, Batch: 94, Loss: 0.6270\n",
      "Epoch: 6, Batch: 95, Loss: 0.7301\n",
      "Epoch: 6, Batch: 96, Loss: 0.7549\n",
      "Epoch: 6, Batch: 97, Loss: 0.5589\n",
      "Epoch: 6, Batch: 98, Loss: 0.6982\n",
      "Epoch: 6, Batch: 99, Loss: 0.5513\n",
      "Epoch: 6, Batch: 100, Loss: 0.7662\n",
      "Epoch: 6, Batch: 101, Loss: 0.7524\n",
      "Epoch: 6, Batch: 102, Loss: 0.8151\n",
      "Epoch: 6, Batch: 103, Loss: 0.6579\n",
      "Epoch: 6, Batch: 104, Loss: 0.5428\n",
      "Epoch: 6, Batch: 105, Loss: 0.6974\n",
      "Epoch: 6, Batch: 106, Loss: 0.5245\n",
      "Epoch: 6, Batch: 107, Loss: 0.5645\n",
      "Epoch: 6, Batch: 108, Loss: 0.6842\n",
      "Epoch: 6, Batch: 109, Loss: 0.6063\n",
      "Epoch: 6, Batch: 110, Loss: 0.5913\n",
      "Epoch: 6, Batch: 111, Loss: 0.5671\n",
      "Epoch: 6, Batch: 112, Loss: 0.4923\n",
      "Epoch: 7, Batch: 0, Loss: 0.6808\n",
      "Epoch: 7, Batch: 1, Loss: 0.6864\n",
      "Epoch: 7, Batch: 2, Loss: 0.5464\n",
      "Epoch: 7, Batch: 3, Loss: 0.6397\n",
      "Epoch: 7, Batch: 4, Loss: 0.5173\n",
      "Epoch: 7, Batch: 5, Loss: 0.5839\n",
      "Epoch: 7, Batch: 6, Loss: 0.6614\n",
      "Epoch: 7, Batch: 7, Loss: 0.8177\n",
      "Epoch: 7, Batch: 8, Loss: 0.5141\n",
      "Epoch: 7, Batch: 9, Loss: 0.6024\n",
      "Epoch: 7, Batch: 10, Loss: 0.6166\n",
      "Epoch: 7, Batch: 11, Loss: 0.4374\n",
      "Epoch: 7, Batch: 12, Loss: 0.4847\n",
      "Epoch: 7, Batch: 13, Loss: 0.5908\n",
      "Epoch: 7, Batch: 14, Loss: 0.4391\n",
      "Epoch: 7, Batch: 15, Loss: 0.4468\n",
      "Epoch: 7, Batch: 16, Loss: 0.7875\n",
      "Epoch: 7, Batch: 17, Loss: 0.6914\n",
      "Epoch: 7, Batch: 18, Loss: 0.7477\n",
      "Epoch: 7, Batch: 19, Loss: 0.6522\n",
      "Epoch: 7, Batch: 20, Loss: 0.9013\n",
      "Epoch: 7, Batch: 21, Loss: 0.4885\n",
      "Epoch: 7, Batch: 22, Loss: 0.6903\n",
      "Epoch: 7, Batch: 23, Loss: 0.6403\n",
      "Epoch: 7, Batch: 24, Loss: 0.5242\n",
      "Epoch: 7, Batch: 25, Loss: 0.7079\n",
      "Epoch: 7, Batch: 26, Loss: 0.7008\n",
      "Epoch: 7, Batch: 27, Loss: 0.7233\n",
      "Epoch: 7, Batch: 28, Loss: 0.6083\n",
      "Epoch: 7, Batch: 29, Loss: 0.6167\n",
      "Epoch: 7, Batch: 30, Loss: 0.5524\n",
      "Epoch: 7, Batch: 31, Loss: 0.6034\n",
      "Epoch: 7, Batch: 32, Loss: 0.6363\n",
      "Epoch: 7, Batch: 33, Loss: 0.6310\n",
      "Epoch: 7, Batch: 34, Loss: 0.6165\n",
      "Epoch: 7, Batch: 35, Loss: 0.7106\n",
      "Epoch: 7, Batch: 36, Loss: 0.5158\n",
      "Epoch: 7, Batch: 37, Loss: 0.6338\n",
      "Epoch: 7, Batch: 38, Loss: 0.7078\n",
      "Epoch: 7, Batch: 39, Loss: 0.5804\n",
      "Epoch: 7, Batch: 40, Loss: 0.4834\n",
      "Epoch: 7, Batch: 41, Loss: 0.5980\n",
      "Epoch: 7, Batch: 42, Loss: 0.6847\n",
      "Epoch: 7, Batch: 43, Loss: 0.6919\n",
      "Epoch: 7, Batch: 44, Loss: 0.6780\n",
      "Epoch: 7, Batch: 45, Loss: 0.5078\n",
      "Epoch: 7, Batch: 46, Loss: 0.7228\n",
      "Epoch: 7, Batch: 47, Loss: 0.5851\n",
      "Epoch: 7, Batch: 48, Loss: 0.6794\n",
      "Epoch: 7, Batch: 49, Loss: 0.5936\n",
      "Epoch: 7, Batch: 50, Loss: 0.6692\n",
      "Epoch: 7, Batch: 51, Loss: 0.6098\n",
      "Epoch: 7, Batch: 52, Loss: 0.6012\n",
      "Epoch: 7, Batch: 53, Loss: 0.5208\n",
      "Epoch: 7, Batch: 54, Loss: 0.6643\n",
      "Epoch: 7, Batch: 55, Loss: 0.5752\n",
      "Epoch: 7, Batch: 56, Loss: 0.5737\n",
      "Epoch: 7, Batch: 57, Loss: 0.7314\n",
      "Epoch: 7, Batch: 58, Loss: 0.5124\n",
      "Epoch: 7, Batch: 59, Loss: 0.5270\n",
      "Epoch: 7, Batch: 60, Loss: 0.5785\n",
      "Epoch: 7, Batch: 61, Loss: 0.6547\n",
      "Epoch: 7, Batch: 62, Loss: 0.6658\n",
      "Epoch: 7, Batch: 63, Loss: 0.5566\n",
      "Epoch: 7, Batch: 64, Loss: 0.5922\n",
      "Epoch: 7, Batch: 65, Loss: 0.6135\n",
      "Epoch: 7, Batch: 66, Loss: 0.6046\n",
      "Epoch: 7, Batch: 67, Loss: 0.7001\n",
      "Epoch: 7, Batch: 68, Loss: 0.6968\n",
      "Epoch: 7, Batch: 69, Loss: 0.6615\n",
      "Epoch: 7, Batch: 70, Loss: 0.4991\n",
      "Epoch: 7, Batch: 71, Loss: 0.5443\n",
      "Epoch: 7, Batch: 72, Loss: 0.5610\n",
      "Epoch: 7, Batch: 73, Loss: 0.5908\n",
      "Epoch: 7, Batch: 74, Loss: 0.6918\n",
      "Epoch: 7, Batch: 75, Loss: 0.6434\n",
      "Epoch: 7, Batch: 76, Loss: 0.5531\n",
      "Epoch: 7, Batch: 77, Loss: 0.6660\n",
      "Epoch: 7, Batch: 78, Loss: 0.6197\n",
      "Epoch: 7, Batch: 79, Loss: 0.4823\n",
      "Epoch: 7, Batch: 80, Loss: 0.3703\n",
      "Epoch: 7, Batch: 81, Loss: 0.6126\n",
      "Epoch: 7, Batch: 82, Loss: 0.4947\n",
      "Epoch: 7, Batch: 83, Loss: 0.6299\n",
      "Epoch: 7, Batch: 84, Loss: 0.6126\n",
      "Epoch: 7, Batch: 85, Loss: 0.6394\n",
      "Epoch: 7, Batch: 86, Loss: 0.5642\n",
      "Epoch: 7, Batch: 87, Loss: 0.5208\n",
      "Epoch: 7, Batch: 88, Loss: 0.5331\n",
      "Epoch: 7, Batch: 89, Loss: 0.5694\n",
      "Epoch: 7, Batch: 90, Loss: 0.7020\n",
      "Epoch: 7, Batch: 91, Loss: 0.5706\n",
      "Epoch: 7, Batch: 92, Loss: 0.4644\n",
      "Epoch: 7, Batch: 93, Loss: 0.4903\n",
      "Epoch: 7, Batch: 94, Loss: 0.6283\n",
      "Epoch: 7, Batch: 95, Loss: 0.7101\n",
      "Epoch: 7, Batch: 96, Loss: 0.7382\n",
      "Epoch: 7, Batch: 97, Loss: 0.5064\n",
      "Epoch: 7, Batch: 98, Loss: 0.7385\n",
      "Epoch: 7, Batch: 99, Loss: 0.4985\n",
      "Epoch: 7, Batch: 100, Loss: 0.8323\n",
      "Epoch: 7, Batch: 101, Loss: 0.7966\n",
      "Epoch: 7, Batch: 102, Loss: 0.7961\n",
      "Epoch: 7, Batch: 103, Loss: 0.6195\n",
      "Epoch: 7, Batch: 104, Loss: 0.5532\n",
      "Epoch: 7, Batch: 105, Loss: 0.7056\n",
      "Epoch: 7, Batch: 106, Loss: 0.4576\n",
      "Epoch: 7, Batch: 107, Loss: 0.5528\n",
      "Epoch: 7, Batch: 108, Loss: 0.6935\n",
      "Epoch: 7, Batch: 109, Loss: 0.6431\n",
      "Epoch: 7, Batch: 110, Loss: 0.5493\n",
      "Epoch: 7, Batch: 111, Loss: 0.5778\n",
      "Epoch: 7, Batch: 112, Loss: 0.3775\n",
      "Epoch: 8, Batch: 0, Loss: 0.7308\n",
      "Epoch: 8, Batch: 1, Loss: 0.6304\n",
      "Epoch: 8, Batch: 2, Loss: 0.4990\n",
      "Epoch: 8, Batch: 3, Loss: 0.6209\n",
      "Epoch: 8, Batch: 4, Loss: 0.4956\n",
      "Epoch: 8, Batch: 5, Loss: 0.5350\n",
      "Epoch: 8, Batch: 6, Loss: 0.6814\n",
      "Epoch: 8, Batch: 7, Loss: 0.7957\n",
      "Epoch: 8, Batch: 8, Loss: 0.4819\n",
      "Epoch: 8, Batch: 9, Loss: 0.5671\n",
      "Epoch: 8, Batch: 10, Loss: 0.5975\n",
      "Epoch: 8, Batch: 11, Loss: 0.3808\n",
      "Epoch: 8, Batch: 12, Loss: 0.4347\n",
      "Epoch: 8, Batch: 13, Loss: 0.5945\n",
      "Epoch: 8, Batch: 14, Loss: 0.4710\n",
      "Epoch: 8, Batch: 15, Loss: 0.4401\n",
      "Epoch: 8, Batch: 16, Loss: 0.7387\n",
      "Epoch: 8, Batch: 17, Loss: 0.7485\n",
      "Epoch: 8, Batch: 18, Loss: 0.7044\n",
      "Epoch: 8, Batch: 19, Loss: 0.6237\n",
      "Epoch: 8, Batch: 20, Loss: 0.9617\n",
      "Epoch: 8, Batch: 21, Loss: 0.5653\n",
      "Epoch: 8, Batch: 22, Loss: 0.6642\n",
      "Epoch: 8, Batch: 23, Loss: 0.6120\n",
      "Epoch: 8, Batch: 24, Loss: 0.5557\n",
      "Epoch: 8, Batch: 25, Loss: 0.6909\n",
      "Epoch: 8, Batch: 26, Loss: 0.6773\n",
      "Epoch: 8, Batch: 27, Loss: 0.6739\n",
      "Epoch: 8, Batch: 28, Loss: 0.5900\n",
      "Epoch: 8, Batch: 29, Loss: 0.6112\n",
      "Epoch: 8, Batch: 30, Loss: 0.5503\n",
      "Epoch: 8, Batch: 31, Loss: 0.6301\n",
      "Epoch: 8, Batch: 32, Loss: 0.6181\n",
      "Epoch: 8, Batch: 33, Loss: 0.5700\n",
      "Epoch: 8, Batch: 34, Loss: 0.6139\n",
      "Epoch: 8, Batch: 35, Loss: 0.7257\n",
      "Epoch: 8, Batch: 36, Loss: 0.4990\n",
      "Epoch: 8, Batch: 37, Loss: 0.6692\n",
      "Epoch: 8, Batch: 38, Loss: 0.6915\n",
      "Epoch: 8, Batch: 39, Loss: 0.5565\n",
      "Epoch: 8, Batch: 40, Loss: 0.4565\n",
      "Epoch: 8, Batch: 41, Loss: 0.5884\n",
      "Epoch: 8, Batch: 42, Loss: 0.6482\n",
      "Epoch: 8, Batch: 43, Loss: 0.6954\n",
      "Epoch: 8, Batch: 44, Loss: 0.6865\n",
      "Epoch: 8, Batch: 45, Loss: 0.5273\n",
      "Epoch: 8, Batch: 46, Loss: 0.7196\n",
      "Epoch: 8, Batch: 47, Loss: 0.5466\n",
      "Epoch: 8, Batch: 48, Loss: 0.6112\n",
      "Epoch: 8, Batch: 49, Loss: 0.6180\n",
      "Epoch: 8, Batch: 50, Loss: 0.6330\n",
      "Epoch: 8, Batch: 51, Loss: 0.5990\n",
      "Epoch: 8, Batch: 52, Loss: 0.5410\n",
      "Epoch: 8, Batch: 53, Loss: 0.5176\n",
      "Epoch: 8, Batch: 54, Loss: 0.6937\n",
      "Epoch: 8, Batch: 55, Loss: 0.5559\n",
      "Epoch: 8, Batch: 56, Loss: 0.5573\n",
      "Epoch: 8, Batch: 57, Loss: 0.6849\n",
      "Epoch: 8, Batch: 58, Loss: 0.5169\n",
      "Epoch: 8, Batch: 59, Loss: 0.5270\n",
      "Epoch: 8, Batch: 60, Loss: 0.5567\n",
      "Epoch: 8, Batch: 61, Loss: 0.6112\n",
      "Epoch: 8, Batch: 62, Loss: 0.6844\n",
      "Epoch: 8, Batch: 63, Loss: 0.5231\n",
      "Epoch: 8, Batch: 64, Loss: 0.6146\n",
      "Epoch: 8, Batch: 65, Loss: 0.6773\n",
      "Epoch: 8, Batch: 66, Loss: 0.6313\n",
      "Epoch: 8, Batch: 67, Loss: 0.7078\n",
      "Epoch: 8, Batch: 68, Loss: 0.6574\n",
      "Epoch: 8, Batch: 69, Loss: 0.6340\n",
      "Epoch: 8, Batch: 70, Loss: 0.5101\n",
      "Epoch: 8, Batch: 71, Loss: 0.5798\n",
      "Epoch: 8, Batch: 72, Loss: 0.5556\n",
      "Epoch: 8, Batch: 73, Loss: 0.6030\n",
      "Epoch: 8, Batch: 74, Loss: 0.6770\n",
      "Epoch: 8, Batch: 75, Loss: 0.6390\n",
      "Epoch: 8, Batch: 76, Loss: 0.5332\n",
      "Epoch: 8, Batch: 77, Loss: 0.6305\n",
      "Epoch: 8, Batch: 78, Loss: 0.6132\n",
      "Epoch: 8, Batch: 79, Loss: 0.4514\n",
      "Epoch: 8, Batch: 80, Loss: 0.3593\n",
      "Epoch: 8, Batch: 81, Loss: 0.6047\n",
      "Epoch: 8, Batch: 82, Loss: 0.4694\n",
      "Epoch: 8, Batch: 83, Loss: 0.6272\n",
      "Epoch: 8, Batch: 84, Loss: 0.5628\n",
      "Epoch: 8, Batch: 85, Loss: 0.6338\n",
      "Epoch: 8, Batch: 86, Loss: 0.5385\n",
      "Epoch: 8, Batch: 87, Loss: 0.4853\n",
      "Epoch: 8, Batch: 88, Loss: 0.5108\n",
      "Epoch: 8, Batch: 89, Loss: 0.5549\n",
      "Epoch: 8, Batch: 90, Loss: 0.7263\n",
      "Epoch: 8, Batch: 91, Loss: 0.5252\n",
      "Epoch: 8, Batch: 92, Loss: 0.4319\n",
      "Epoch: 8, Batch: 93, Loss: 0.4819\n",
      "Epoch: 8, Batch: 94, Loss: 0.6052\n",
      "Epoch: 8, Batch: 95, Loss: 0.7176\n",
      "Epoch: 8, Batch: 96, Loss: 0.7606\n",
      "Epoch: 8, Batch: 97, Loss: 0.4932\n",
      "Epoch: 8, Batch: 98, Loss: 0.7057\n",
      "Epoch: 8, Batch: 99, Loss: 0.5728\n",
      "Epoch: 8, Batch: 100, Loss: 0.8058\n",
      "Epoch: 8, Batch: 101, Loss: 0.7694\n",
      "Epoch: 8, Batch: 102, Loss: 0.8057\n",
      "Epoch: 8, Batch: 103, Loss: 0.6137\n",
      "Epoch: 8, Batch: 104, Loss: 0.5134\n",
      "Epoch: 8, Batch: 105, Loss: 0.7495\n",
      "Epoch: 8, Batch: 106, Loss: 0.4437\n",
      "Epoch: 8, Batch: 107, Loss: 0.5567\n",
      "Epoch: 8, Batch: 108, Loss: 0.6591\n",
      "Epoch: 8, Batch: 109, Loss: 0.5650\n",
      "Epoch: 8, Batch: 110, Loss: 0.5626\n",
      "Epoch: 8, Batch: 111, Loss: 0.5169\n",
      "Epoch: 8, Batch: 112, Loss: 0.3644\n",
      "Epoch: 9, Batch: 0, Loss: 0.7117\n",
      "Epoch: 9, Batch: 1, Loss: 0.7098\n",
      "Epoch: 9, Batch: 2, Loss: 0.5072\n",
      "Epoch: 9, Batch: 3, Loss: 0.6071\n",
      "Epoch: 9, Batch: 4, Loss: 0.4985\n",
      "Epoch: 9, Batch: 5, Loss: 0.5376\n",
      "Epoch: 9, Batch: 6, Loss: 0.6579\n",
      "Epoch: 9, Batch: 7, Loss: 0.8551\n",
      "Epoch: 9, Batch: 8, Loss: 0.4689\n",
      "Epoch: 9, Batch: 9, Loss: 0.5250\n",
      "Epoch: 9, Batch: 10, Loss: 0.6172\n",
      "Epoch: 9, Batch: 11, Loss: 0.3847\n",
      "Epoch: 9, Batch: 12, Loss: 0.4225\n",
      "Epoch: 9, Batch: 13, Loss: 0.5604\n",
      "Epoch: 9, Batch: 14, Loss: 0.3948\n",
      "Epoch: 9, Batch: 15, Loss: 0.4320\n",
      "Epoch: 9, Batch: 16, Loss: 0.7602\n",
      "Epoch: 9, Batch: 17, Loss: 0.6589\n",
      "Epoch: 9, Batch: 18, Loss: 0.6442\n",
      "Epoch: 9, Batch: 19, Loss: 0.5816\n",
      "Epoch: 9, Batch: 20, Loss: 0.9449\n",
      "Epoch: 9, Batch: 21, Loss: 0.5078\n",
      "Epoch: 9, Batch: 22, Loss: 0.6025\n",
      "Epoch: 9, Batch: 23, Loss: 0.5415\n",
      "Epoch: 9, Batch: 24, Loss: 0.5392\n",
      "Epoch: 9, Batch: 25, Loss: 0.6687\n",
      "Epoch: 9, Batch: 26, Loss: 0.6948\n",
      "Epoch: 9, Batch: 27, Loss: 0.6967\n",
      "Epoch: 9, Batch: 28, Loss: 0.5533\n",
      "Epoch: 9, Batch: 29, Loss: 0.6188\n",
      "Epoch: 9, Batch: 30, Loss: 0.5317\n",
      "Epoch: 9, Batch: 31, Loss: 0.5794\n",
      "Epoch: 9, Batch: 32, Loss: 0.6194\n",
      "Epoch: 9, Batch: 33, Loss: 0.6404\n",
      "Epoch: 9, Batch: 34, Loss: 0.5786\n",
      "Epoch: 9, Batch: 35, Loss: 0.6940\n",
      "Epoch: 9, Batch: 36, Loss: 0.5070\n",
      "Epoch: 9, Batch: 37, Loss: 0.6780\n",
      "Epoch: 9, Batch: 38, Loss: 0.6888\n",
      "Epoch: 9, Batch: 39, Loss: 0.5569\n",
      "Epoch: 9, Batch: 40, Loss: 0.4224\n",
      "Epoch: 9, Batch: 41, Loss: 0.5909\n",
      "Epoch: 9, Batch: 42, Loss: 0.7174\n",
      "Epoch: 9, Batch: 43, Loss: 0.7441\n",
      "Epoch: 9, Batch: 44, Loss: 0.6366\n",
      "Epoch: 9, Batch: 45, Loss: 0.4663\n",
      "Epoch: 9, Batch: 46, Loss: 0.7183\n",
      "Epoch: 9, Batch: 47, Loss: 0.5260\n",
      "Epoch: 9, Batch: 48, Loss: 0.6475\n",
      "Epoch: 9, Batch: 49, Loss: 0.6065\n",
      "Epoch: 9, Batch: 50, Loss: 0.6317\n",
      "Epoch: 9, Batch: 51, Loss: 0.5681\n",
      "Epoch: 9, Batch: 52, Loss: 0.5883\n",
      "Epoch: 9, Batch: 53, Loss: 0.4863\n",
      "Epoch: 9, Batch: 54, Loss: 0.6640\n",
      "Epoch: 9, Batch: 55, Loss: 0.5641\n",
      "Epoch: 9, Batch: 56, Loss: 0.4633\n",
      "Epoch: 9, Batch: 57, Loss: 0.7188\n",
      "Epoch: 9, Batch: 58, Loss: 0.5175\n",
      "Epoch: 9, Batch: 59, Loss: 0.4348\n",
      "Epoch: 9, Batch: 60, Loss: 0.5561\n",
      "Epoch: 9, Batch: 61, Loss: 0.6191\n",
      "Epoch: 9, Batch: 62, Loss: 0.7239\n",
      "Epoch: 9, Batch: 63, Loss: 0.5270\n",
      "Epoch: 9, Batch: 64, Loss: 0.6001\n",
      "Epoch: 9, Batch: 65, Loss: 0.6046\n",
      "Epoch: 9, Batch: 66, Loss: 0.6663\n",
      "Epoch: 9, Batch: 67, Loss: 0.7132\n",
      "Epoch: 9, Batch: 68, Loss: 0.5865\n",
      "Epoch: 9, Batch: 69, Loss: 0.6709\n",
      "Epoch: 9, Batch: 70, Loss: 0.4964\n",
      "Epoch: 9, Batch: 71, Loss: 0.5673\n",
      "Epoch: 9, Batch: 72, Loss: 0.4918\n",
      "Epoch: 9, Batch: 73, Loss: 0.5539\n",
      "Epoch: 9, Batch: 74, Loss: 0.6920\n",
      "Epoch: 9, Batch: 75, Loss: 0.5810\n",
      "Epoch: 9, Batch: 76, Loss: 0.5151\n",
      "Epoch: 9, Batch: 77, Loss: 0.6145\n",
      "Epoch: 9, Batch: 78, Loss: 0.6368\n",
      "Epoch: 9, Batch: 79, Loss: 0.4587\n",
      "Epoch: 9, Batch: 80, Loss: 0.3207\n",
      "Epoch: 9, Batch: 81, Loss: 0.5788\n",
      "Epoch: 9, Batch: 82, Loss: 0.4550\n",
      "Epoch: 9, Batch: 83, Loss: 0.7034\n",
      "Epoch: 9, Batch: 84, Loss: 0.6113\n",
      "Epoch: 9, Batch: 85, Loss: 0.6401\n",
      "Epoch: 9, Batch: 86, Loss: 0.5484\n",
      "Epoch: 9, Batch: 87, Loss: 0.4873\n",
      "Epoch: 9, Batch: 88, Loss: 0.5159\n",
      "Epoch: 9, Batch: 89, Loss: 0.5910\n",
      "Epoch: 9, Batch: 90, Loss: 0.6736\n",
      "Epoch: 9, Batch: 91, Loss: 0.5267\n",
      "Epoch: 9, Batch: 92, Loss: 0.4217\n",
      "Epoch: 9, Batch: 93, Loss: 0.4171\n",
      "Epoch: 9, Batch: 94, Loss: 0.5807\n",
      "Epoch: 9, Batch: 95, Loss: 0.7366\n",
      "Epoch: 9, Batch: 96, Loss: 0.7755\n",
      "Epoch: 9, Batch: 97, Loss: 0.5151\n",
      "Epoch: 9, Batch: 98, Loss: 0.7006\n",
      "Epoch: 9, Batch: 99, Loss: 0.5317\n",
      "Epoch: 9, Batch: 100, Loss: 0.8259\n",
      "Epoch: 9, Batch: 101, Loss: 0.7529\n",
      "Epoch: 9, Batch: 102, Loss: 0.7721\n",
      "Epoch: 9, Batch: 103, Loss: 0.6272\n",
      "Epoch: 9, Batch: 104, Loss: 0.4881\n",
      "Epoch: 9, Batch: 105, Loss: 0.7278\n",
      "Epoch: 9, Batch: 106, Loss: 0.4204\n",
      "Epoch: 9, Batch: 107, Loss: 0.5551\n",
      "Epoch: 9, Batch: 108, Loss: 0.6591\n",
      "Epoch: 9, Batch: 109, Loss: 0.6049\n",
      "Epoch: 9, Batch: 110, Loss: 0.5730\n",
      "Epoch: 9, Batch: 111, Loss: 0.5339\n",
      "Epoch: 9, Batch: 112, Loss: 0.3793\n",
      "Epoch: 10, Batch: 0, Loss: 0.7022\n",
      "Epoch: 10, Batch: 1, Loss: 0.7124\n",
      "Epoch: 10, Batch: 2, Loss: 0.4981\n",
      "Epoch: 10, Batch: 3, Loss: 0.5558\n",
      "Epoch: 10, Batch: 4, Loss: 0.4442\n",
      "Epoch: 10, Batch: 5, Loss: 0.5701\n",
      "Epoch: 10, Batch: 6, Loss: 0.6944\n",
      "Epoch: 10, Batch: 7, Loss: 0.8113\n",
      "Epoch: 10, Batch: 8, Loss: 0.4020\n",
      "Epoch: 10, Batch: 9, Loss: 0.5600\n",
      "Epoch: 10, Batch: 10, Loss: 0.6292\n",
      "Epoch: 10, Batch: 11, Loss: 0.3374\n",
      "Epoch: 10, Batch: 12, Loss: 0.4085\n",
      "Epoch: 10, Batch: 13, Loss: 0.5631\n",
      "Epoch: 10, Batch: 14, Loss: 0.4272\n",
      "Epoch: 10, Batch: 15, Loss: 0.4146\n",
      "Epoch: 10, Batch: 16, Loss: 0.6254\n",
      "Epoch: 10, Batch: 17, Loss: 0.6611\n",
      "Epoch: 10, Batch: 18, Loss: 0.6621\n",
      "Epoch: 10, Batch: 19, Loss: 0.5736\n",
      "Epoch: 10, Batch: 20, Loss: 0.9776\n",
      "Epoch: 10, Batch: 21, Loss: 0.4694\n",
      "Epoch: 10, Batch: 22, Loss: 0.6467\n",
      "Epoch: 10, Batch: 23, Loss: 0.5915\n",
      "Epoch: 10, Batch: 24, Loss: 0.5180\n",
      "Epoch: 10, Batch: 25, Loss: 0.6691\n",
      "Epoch: 10, Batch: 26, Loss: 0.6850\n",
      "Epoch: 10, Batch: 27, Loss: 0.6742\n",
      "Epoch: 10, Batch: 28, Loss: 0.5553\n",
      "Epoch: 10, Batch: 29, Loss: 0.5913\n",
      "Epoch: 10, Batch: 30, Loss: 0.5550\n",
      "Epoch: 10, Batch: 31, Loss: 0.5953\n",
      "Epoch: 10, Batch: 32, Loss: 0.5992\n",
      "Epoch: 10, Batch: 33, Loss: 0.6290\n",
      "Epoch: 10, Batch: 34, Loss: 0.6102\n",
      "Epoch: 10, Batch: 35, Loss: 0.7286\n",
      "Epoch: 10, Batch: 36, Loss: 0.4516\n",
      "Epoch: 10, Batch: 37, Loss: 0.6376\n",
      "Epoch: 10, Batch: 38, Loss: 0.6724\n",
      "Epoch: 10, Batch: 39, Loss: 0.4609\n",
      "Epoch: 10, Batch: 40, Loss: 0.4014\n",
      "Epoch: 10, Batch: 41, Loss: 0.5617\n",
      "Epoch: 10, Batch: 42, Loss: 0.7134\n",
      "Epoch: 10, Batch: 43, Loss: 0.6959\n",
      "Epoch: 10, Batch: 44, Loss: 0.6308\n",
      "Epoch: 10, Batch: 45, Loss: 0.4532\n",
      "Epoch: 10, Batch: 46, Loss: 0.7368\n",
      "Epoch: 10, Batch: 47, Loss: 0.5492\n",
      "Epoch: 10, Batch: 48, Loss: 0.6226\n",
      "Epoch: 10, Batch: 49, Loss: 0.5778\n",
      "Epoch: 10, Batch: 50, Loss: 0.6560\n",
      "Epoch: 10, Batch: 51, Loss: 0.5849\n",
      "Epoch: 10, Batch: 52, Loss: 0.5789\n",
      "Epoch: 10, Batch: 53, Loss: 0.5075\n",
      "Epoch: 10, Batch: 54, Loss: 0.6492\n",
      "Epoch: 10, Batch: 55, Loss: 0.5155\n",
      "Epoch: 10, Batch: 56, Loss: 0.4387\n",
      "Epoch: 10, Batch: 57, Loss: 0.6984\n",
      "Epoch: 10, Batch: 58, Loss: 0.4702\n",
      "Epoch: 10, Batch: 59, Loss: 0.4486\n",
      "Epoch: 10, Batch: 60, Loss: 0.5973\n",
      "Epoch: 10, Batch: 61, Loss: 0.6207\n",
      "Epoch: 10, Batch: 62, Loss: 0.6919\n",
      "Epoch: 10, Batch: 63, Loss: 0.4933\n",
      "Epoch: 10, Batch: 64, Loss: 0.5922\n",
      "Epoch: 10, Batch: 65, Loss: 0.5826\n",
      "Epoch: 10, Batch: 66, Loss: 0.6008\n",
      "Epoch: 10, Batch: 67, Loss: 0.6845\n",
      "Epoch: 10, Batch: 68, Loss: 0.6504\n",
      "Epoch: 10, Batch: 69, Loss: 0.6846\n",
      "Epoch: 10, Batch: 70, Loss: 0.4712\n",
      "Epoch: 10, Batch: 71, Loss: 0.5423\n",
      "Epoch: 10, Batch: 72, Loss: 0.5492\n",
      "Epoch: 10, Batch: 73, Loss: 0.6029\n",
      "Epoch: 10, Batch: 74, Loss: 0.6343\n",
      "Epoch: 10, Batch: 75, Loss: 0.6088\n",
      "Epoch: 10, Batch: 76, Loss: 0.4856\n",
      "Epoch: 10, Batch: 77, Loss: 0.6400\n",
      "Epoch: 10, Batch: 78, Loss: 0.5748\n",
      "Epoch: 10, Batch: 79, Loss: 0.4645\n",
      "Epoch: 10, Batch: 80, Loss: 0.3278\n",
      "Epoch: 10, Batch: 81, Loss: 0.5821\n",
      "Epoch: 10, Batch: 82, Loss: 0.4469\n",
      "Epoch: 10, Batch: 83, Loss: 0.6300\n",
      "Epoch: 10, Batch: 84, Loss: 0.6134\n",
      "Epoch: 10, Batch: 85, Loss: 0.6235\n",
      "Epoch: 10, Batch: 86, Loss: 0.6085\n",
      "Epoch: 10, Batch: 87, Loss: 0.4621\n",
      "Epoch: 10, Batch: 88, Loss: 0.5082\n",
      "Epoch: 10, Batch: 89, Loss: 0.5395\n",
      "Epoch: 10, Batch: 90, Loss: 0.7146\n",
      "Epoch: 10, Batch: 91, Loss: 0.5159\n",
      "Epoch: 10, Batch: 92, Loss: 0.4087\n",
      "Epoch: 10, Batch: 93, Loss: 0.4243\n",
      "Epoch: 10, Batch: 94, Loss: 0.5370\n",
      "Epoch: 10, Batch: 95, Loss: 0.7310\n",
      "Epoch: 10, Batch: 96, Loss: 0.7663\n",
      "Epoch: 10, Batch: 97, Loss: 0.4957\n",
      "Epoch: 10, Batch: 98, Loss: 0.7215\n",
      "Epoch: 10, Batch: 99, Loss: 0.5490\n",
      "Epoch: 10, Batch: 100, Loss: 0.8106\n",
      "Epoch: 10, Batch: 101, Loss: 0.8807\n",
      "Epoch: 10, Batch: 102, Loss: 0.8286\n",
      "Epoch: 10, Batch: 103, Loss: 0.5615\n",
      "Epoch: 10, Batch: 104, Loss: 0.4963\n",
      "Epoch: 10, Batch: 105, Loss: 0.7668\n",
      "Epoch: 10, Batch: 106, Loss: 0.4440\n",
      "Epoch: 10, Batch: 107, Loss: 0.5751\n",
      "Epoch: 10, Batch: 108, Loss: 0.6949\n",
      "Epoch: 10, Batch: 109, Loss: 0.6028\n",
      "Epoch: 10, Batch: 110, Loss: 0.4792\n",
      "Epoch: 10, Batch: 111, Loss: 0.4794\n",
      "Epoch: 10, Batch: 112, Loss: 0.3600\n",
      "Epoch: 11, Batch: 0, Loss: 0.7714\n",
      "Epoch: 11, Batch: 1, Loss: 0.7467\n",
      "Epoch: 11, Batch: 2, Loss: 0.5254\n",
      "Epoch: 11, Batch: 3, Loss: 0.5470\n",
      "Epoch: 11, Batch: 4, Loss: 0.4573\n",
      "Epoch: 11, Batch: 5, Loss: 0.5165\n",
      "Epoch: 11, Batch: 6, Loss: 0.6830\n",
      "Epoch: 11, Batch: 7, Loss: 0.8434\n",
      "Epoch: 11, Batch: 8, Loss: 0.4241\n",
      "Epoch: 11, Batch: 9, Loss: 0.5656\n",
      "Epoch: 11, Batch: 10, Loss: 0.6618\n",
      "Epoch: 11, Batch: 11, Loss: 0.3257\n",
      "Epoch: 11, Batch: 12, Loss: 0.4009\n",
      "Epoch: 11, Batch: 13, Loss: 0.5118\n",
      "Epoch: 11, Batch: 14, Loss: 0.4136\n",
      "Epoch: 11, Batch: 15, Loss: 0.4766\n",
      "Epoch: 11, Batch: 16, Loss: 0.5721\n",
      "Epoch: 11, Batch: 17, Loss: 0.6232\n",
      "Epoch: 11, Batch: 18, Loss: 0.6732\n",
      "Epoch: 11, Batch: 19, Loss: 0.5580\n",
      "Epoch: 11, Batch: 20, Loss: 0.9296\n",
      "Epoch: 11, Batch: 21, Loss: 0.5135\n",
      "Epoch: 11, Batch: 22, Loss: 0.6498\n",
      "Epoch: 11, Batch: 23, Loss: 0.5630\n",
      "Epoch: 11, Batch: 24, Loss: 0.5540\n",
      "Epoch: 11, Batch: 25, Loss: 0.6173\n",
      "Epoch: 11, Batch: 26, Loss: 0.6819\n",
      "Epoch: 11, Batch: 27, Loss: 0.7051\n",
      "Epoch: 11, Batch: 28, Loss: 0.5344\n",
      "Epoch: 11, Batch: 29, Loss: 0.5491\n",
      "Epoch: 11, Batch: 30, Loss: 0.5252\n",
      "Epoch: 11, Batch: 31, Loss: 0.6145\n",
      "Epoch: 11, Batch: 32, Loss: 0.5753\n",
      "Epoch: 11, Batch: 33, Loss: 0.6174\n",
      "Epoch: 11, Batch: 34, Loss: 0.5812\n",
      "Epoch: 11, Batch: 35, Loss: 0.7394\n",
      "Epoch: 11, Batch: 36, Loss: 0.4692\n",
      "Epoch: 11, Batch: 37, Loss: 0.6933\n",
      "Epoch: 11, Batch: 38, Loss: 0.7441\n",
      "Epoch: 11, Batch: 39, Loss: 0.5199\n",
      "Epoch: 11, Batch: 40, Loss: 0.3552\n",
      "Epoch: 11, Batch: 41, Loss: 0.5748\n",
      "Epoch: 11, Batch: 42, Loss: 0.7018\n",
      "Epoch: 11, Batch: 43, Loss: 0.7412\n",
      "Epoch: 11, Batch: 44, Loss: 0.6479\n",
      "Epoch: 11, Batch: 45, Loss: 0.4442\n",
      "Epoch: 11, Batch: 46, Loss: 0.6786\n",
      "Epoch: 11, Batch: 47, Loss: 0.5308\n",
      "Epoch: 11, Batch: 48, Loss: 0.6176\n",
      "Epoch: 11, Batch: 49, Loss: 0.6142\n",
      "Epoch: 11, Batch: 50, Loss: 0.6327\n",
      "Epoch: 11, Batch: 51, Loss: 0.5668\n",
      "Epoch: 11, Batch: 52, Loss: 0.5149\n",
      "Epoch: 11, Batch: 53, Loss: 0.4803\n",
      "Epoch: 11, Batch: 54, Loss: 0.7069\n",
      "Epoch: 11, Batch: 55, Loss: 0.5221\n",
      "Epoch: 11, Batch: 56, Loss: 0.4080\n",
      "Epoch: 11, Batch: 57, Loss: 0.6151\n",
      "Epoch: 11, Batch: 58, Loss: 0.5020\n",
      "Epoch: 11, Batch: 59, Loss: 0.4846\n",
      "Epoch: 11, Batch: 60, Loss: 0.5500\n",
      "Epoch: 11, Batch: 61, Loss: 0.5901\n",
      "Epoch: 11, Batch: 62, Loss: 0.6523\n",
      "Epoch: 11, Batch: 63, Loss: 0.4624\n",
      "Epoch: 11, Batch: 64, Loss: 0.5623\n",
      "Epoch: 11, Batch: 65, Loss: 0.6350\n",
      "Epoch: 11, Batch: 66, Loss: 0.6194\n",
      "Epoch: 11, Batch: 67, Loss: 0.6318\n",
      "Epoch: 11, Batch: 68, Loss: 0.6192\n",
      "Epoch: 11, Batch: 69, Loss: 0.6665\n",
      "Epoch: 11, Batch: 70, Loss: 0.4855\n",
      "Epoch: 11, Batch: 71, Loss: 0.5125\n",
      "Epoch: 11, Batch: 72, Loss: 0.5416\n",
      "Epoch: 11, Batch: 73, Loss: 0.6191\n",
      "Epoch: 11, Batch: 74, Loss: 0.6641\n",
      "Epoch: 11, Batch: 75, Loss: 0.5649\n",
      "Epoch: 11, Batch: 76, Loss: 0.5097\n",
      "Epoch: 11, Batch: 77, Loss: 0.6285\n",
      "Epoch: 11, Batch: 78, Loss: 0.6423\n",
      "Epoch: 11, Batch: 79, Loss: 0.4521\n",
      "Epoch: 11, Batch: 80, Loss: 0.3177\n",
      "Epoch: 11, Batch: 81, Loss: 0.5456\n",
      "Epoch: 11, Batch: 82, Loss: 0.4017\n",
      "Epoch: 11, Batch: 83, Loss: 0.6719\n",
      "Epoch: 11, Batch: 84, Loss: 0.6359\n",
      "Epoch: 11, Batch: 85, Loss: 0.6274\n",
      "Epoch: 11, Batch: 86, Loss: 0.5791\n",
      "Epoch: 11, Batch: 87, Loss: 0.4500\n",
      "Epoch: 11, Batch: 88, Loss: 0.5017\n",
      "Epoch: 11, Batch: 89, Loss: 0.5600\n",
      "Epoch: 11, Batch: 90, Loss: 0.6652\n",
      "Epoch: 11, Batch: 91, Loss: 0.5560\n",
      "Epoch: 11, Batch: 92, Loss: 0.4091\n",
      "Epoch: 11, Batch: 93, Loss: 0.4372\n",
      "Epoch: 11, Batch: 94, Loss: 0.5504\n",
      "Epoch: 11, Batch: 95, Loss: 0.7216\n",
      "Epoch: 11, Batch: 96, Loss: 0.7942\n",
      "Epoch: 11, Batch: 97, Loss: 0.4591\n",
      "Epoch: 11, Batch: 98, Loss: 0.7144\n",
      "Epoch: 11, Batch: 99, Loss: 0.5252\n",
      "Epoch: 11, Batch: 100, Loss: 0.8318\n",
      "Epoch: 11, Batch: 101, Loss: 0.8235\n",
      "Epoch: 11, Batch: 102, Loss: 0.7673\n",
      "Epoch: 11, Batch: 103, Loss: 0.5627\n",
      "Epoch: 11, Batch: 104, Loss: 0.4433\n",
      "Epoch: 11, Batch: 105, Loss: 0.6887\n",
      "Epoch: 11, Batch: 106, Loss: 0.3709\n",
      "Epoch: 11, Batch: 107, Loss: 0.5413\n",
      "Epoch: 11, Batch: 108, Loss: 0.6488\n",
      "Epoch: 11, Batch: 109, Loss: 0.5698\n",
      "Epoch: 11, Batch: 110, Loss: 0.5441\n",
      "Epoch: 11, Batch: 111, Loss: 0.4506\n",
      "Epoch: 11, Batch: 112, Loss: 0.3684\n",
      "Epoch: 12, Batch: 0, Loss: 0.6950\n",
      "Epoch: 12, Batch: 1, Loss: 0.7160\n",
      "Epoch: 12, Batch: 2, Loss: 0.5270\n",
      "Epoch: 12, Batch: 3, Loss: 0.5089\n",
      "Epoch: 12, Batch: 4, Loss: 0.4286\n",
      "Epoch: 12, Batch: 5, Loss: 0.5355\n",
      "Epoch: 12, Batch: 6, Loss: 0.6750\n",
      "Epoch: 12, Batch: 7, Loss: 0.8018\n",
      "Epoch: 12, Batch: 8, Loss: 0.4316\n",
      "Epoch: 12, Batch: 9, Loss: 0.5104\n",
      "Epoch: 12, Batch: 10, Loss: 0.6968\n",
      "Epoch: 12, Batch: 11, Loss: 0.3104\n",
      "Epoch: 12, Batch: 12, Loss: 0.4127\n",
      "Epoch: 12, Batch: 13, Loss: 0.4470\n",
      "Epoch: 12, Batch: 14, Loss: 0.4291\n",
      "Epoch: 12, Batch: 15, Loss: 0.4845\n",
      "Epoch: 12, Batch: 16, Loss: 0.5856\n",
      "Epoch: 12, Batch: 17, Loss: 0.6124\n",
      "Epoch: 12, Batch: 18, Loss: 0.6004\n",
      "Epoch: 12, Batch: 19, Loss: 0.5676\n",
      "Epoch: 12, Batch: 20, Loss: 0.8689\n",
      "Epoch: 12, Batch: 21, Loss: 0.4520\n",
      "Epoch: 12, Batch: 22, Loss: 0.6128\n",
      "Epoch: 12, Batch: 23, Loss: 0.5856\n",
      "Epoch: 12, Batch: 24, Loss: 0.5474\n",
      "Epoch: 12, Batch: 25, Loss: 0.6226\n",
      "Epoch: 12, Batch: 26, Loss: 0.6564\n",
      "Epoch: 12, Batch: 27, Loss: 0.7513\n",
      "Epoch: 12, Batch: 28, Loss: 0.5752\n",
      "Epoch: 12, Batch: 29, Loss: 0.5990\n",
      "Epoch: 12, Batch: 30, Loss: 0.4700\n",
      "Epoch: 12, Batch: 31, Loss: 0.6328\n",
      "Epoch: 12, Batch: 32, Loss: 0.6121\n",
      "Epoch: 12, Batch: 33, Loss: 0.6936\n",
      "Epoch: 12, Batch: 34, Loss: 0.5630\n",
      "Epoch: 12, Batch: 35, Loss: 0.6765\n",
      "Epoch: 12, Batch: 36, Loss: 0.5204\n",
      "Epoch: 12, Batch: 37, Loss: 0.6545\n",
      "Epoch: 12, Batch: 38, Loss: 0.6577\n",
      "Epoch: 12, Batch: 39, Loss: 0.5109\n",
      "Epoch: 12, Batch: 40, Loss: 0.3307\n",
      "Epoch: 12, Batch: 41, Loss: 0.5263\n",
      "Epoch: 12, Batch: 42, Loss: 0.7401\n",
      "Epoch: 12, Batch: 43, Loss: 0.7326\n",
      "Epoch: 12, Batch: 44, Loss: 0.6027\n",
      "Epoch: 12, Batch: 45, Loss: 0.4540\n",
      "Epoch: 12, Batch: 46, Loss: 0.7220\n",
      "Epoch: 12, Batch: 47, Loss: 0.5384\n",
      "Epoch: 12, Batch: 48, Loss: 0.6276\n",
      "Epoch: 12, Batch: 49, Loss: 0.6181\n",
      "Epoch: 12, Batch: 50, Loss: 0.6233\n",
      "Epoch: 12, Batch: 51, Loss: 0.6321\n",
      "Epoch: 12, Batch: 52, Loss: 0.5304\n",
      "Epoch: 12, Batch: 53, Loss: 0.4759\n",
      "Epoch: 12, Batch: 54, Loss: 0.6956\n",
      "Epoch: 12, Batch: 55, Loss: 0.5149\n",
      "Epoch: 12, Batch: 56, Loss: 0.4137\n",
      "Epoch: 12, Batch: 57, Loss: 0.6195\n",
      "Epoch: 12, Batch: 58, Loss: 0.4482\n",
      "Epoch: 12, Batch: 59, Loss: 0.4823\n",
      "Epoch: 12, Batch: 60, Loss: 0.5324\n",
      "Epoch: 12, Batch: 61, Loss: 0.5577\n",
      "Epoch: 12, Batch: 62, Loss: 0.6568\n",
      "Epoch: 12, Batch: 63, Loss: 0.4695\n",
      "Epoch: 12, Batch: 64, Loss: 0.5689\n",
      "Epoch: 12, Batch: 65, Loss: 0.6078\n",
      "Epoch: 12, Batch: 66, Loss: 0.6081\n",
      "Epoch: 12, Batch: 67, Loss: 0.6993\n",
      "Epoch: 12, Batch: 68, Loss: 0.6183\n",
      "Epoch: 12, Batch: 69, Loss: 0.6113\n",
      "Epoch: 12, Batch: 70, Loss: 0.4785\n",
      "Epoch: 12, Batch: 71, Loss: 0.5384\n",
      "Epoch: 12, Batch: 72, Loss: 0.5852\n",
      "Epoch: 12, Batch: 73, Loss: 0.5618\n",
      "Epoch: 12, Batch: 74, Loss: 0.6648\n",
      "Epoch: 12, Batch: 75, Loss: 0.5472\n",
      "Epoch: 12, Batch: 76, Loss: 0.4816\n",
      "Epoch: 12, Batch: 77, Loss: 0.6188\n",
      "Epoch: 12, Batch: 78, Loss: 0.5548\n",
      "Epoch: 12, Batch: 79, Loss: 0.4682\n",
      "Epoch: 12, Batch: 80, Loss: 0.3202\n",
      "Epoch: 12, Batch: 81, Loss: 0.5559\n",
      "Epoch: 12, Batch: 82, Loss: 0.4208\n",
      "Epoch: 12, Batch: 83, Loss: 0.6587\n",
      "Epoch: 12, Batch: 84, Loss: 0.5718\n",
      "Epoch: 12, Batch: 85, Loss: 0.5784\n",
      "Epoch: 12, Batch: 86, Loss: 0.6214\n",
      "Epoch: 12, Batch: 87, Loss: 0.4646\n",
      "Epoch: 12, Batch: 88, Loss: 0.4520\n",
      "Epoch: 12, Batch: 89, Loss: 0.5211\n",
      "Epoch: 12, Batch: 90, Loss: 0.6487\n",
      "Epoch: 12, Batch: 91, Loss: 0.4884\n",
      "Epoch: 12, Batch: 92, Loss: 0.4078\n",
      "Epoch: 12, Batch: 93, Loss: 0.4052\n",
      "Epoch: 12, Batch: 94, Loss: 0.5827\n",
      "Epoch: 12, Batch: 95, Loss: 0.7825\n",
      "Epoch: 12, Batch: 96, Loss: 0.7126\n",
      "Epoch: 12, Batch: 97, Loss: 0.4520\n",
      "Epoch: 12, Batch: 98, Loss: 0.6550\n",
      "Epoch: 12, Batch: 99, Loss: 0.5433\n",
      "Epoch: 12, Batch: 100, Loss: 0.8578\n",
      "Epoch: 12, Batch: 101, Loss: 0.8115\n",
      "Epoch: 12, Batch: 102, Loss: 0.7915\n",
      "Epoch: 12, Batch: 103, Loss: 0.5287\n",
      "Epoch: 12, Batch: 104, Loss: 0.4457\n",
      "Epoch: 12, Batch: 105, Loss: 0.6358\n",
      "Epoch: 12, Batch: 106, Loss: 0.3734\n",
      "Epoch: 12, Batch: 107, Loss: 0.5324\n",
      "Epoch: 12, Batch: 108, Loss: 0.6780\n",
      "Epoch: 12, Batch: 109, Loss: 0.6598\n",
      "Epoch: 12, Batch: 110, Loss: 0.4987\n",
      "Epoch: 12, Batch: 111, Loss: 0.4538\n",
      "Epoch: 12, Batch: 112, Loss: 0.3909\n",
      "Epoch: 13, Batch: 0, Loss: 0.7202\n",
      "Epoch: 13, Batch: 1, Loss: 0.7012\n",
      "Epoch: 13, Batch: 2, Loss: 0.5715\n",
      "Epoch: 13, Batch: 3, Loss: 0.4804\n",
      "Epoch: 13, Batch: 4, Loss: 0.3992\n",
      "Epoch: 13, Batch: 5, Loss: 0.4575\n",
      "Epoch: 13, Batch: 6, Loss: 0.7244\n",
      "Epoch: 13, Batch: 7, Loss: 0.8716\n",
      "Epoch: 13, Batch: 8, Loss: 0.4474\n",
      "Epoch: 13, Batch: 9, Loss: 0.5539\n",
      "Epoch: 13, Batch: 10, Loss: 0.6369\n",
      "Epoch: 13, Batch: 11, Loss: 0.2925\n",
      "Epoch: 13, Batch: 12, Loss: 0.3740\n",
      "Epoch: 13, Batch: 13, Loss: 0.4686\n",
      "Epoch: 13, Batch: 14, Loss: 0.3784\n",
      "Epoch: 13, Batch: 15, Loss: 0.4325\n",
      "Epoch: 13, Batch: 16, Loss: 0.5638\n",
      "Epoch: 13, Batch: 17, Loss: 0.5629\n",
      "Epoch: 13, Batch: 18, Loss: 0.5757\n",
      "Epoch: 13, Batch: 19, Loss: 0.5752\n",
      "Epoch: 13, Batch: 20, Loss: 0.8992\n",
      "Epoch: 13, Batch: 21, Loss: 0.4998\n",
      "Epoch: 13, Batch: 22, Loss: 0.6087\n",
      "Epoch: 13, Batch: 23, Loss: 0.5421\n",
      "Epoch: 13, Batch: 24, Loss: 0.5690\n",
      "Epoch: 13, Batch: 25, Loss: 0.6142\n",
      "Epoch: 13, Batch: 26, Loss: 0.6356\n",
      "Epoch: 13, Batch: 27, Loss: 0.7593\n",
      "Epoch: 13, Batch: 28, Loss: 0.5959\n",
      "Epoch: 13, Batch: 29, Loss: 0.5796\n",
      "Epoch: 13, Batch: 30, Loss: 0.5043\n",
      "Epoch: 13, Batch: 31, Loss: 0.6263\n",
      "Epoch: 13, Batch: 32, Loss: 0.5947\n",
      "Epoch: 13, Batch: 33, Loss: 0.6582\n",
      "Epoch: 13, Batch: 34, Loss: 0.5635\n",
      "Epoch: 13, Batch: 35, Loss: 0.6560\n",
      "Epoch: 13, Batch: 36, Loss: 0.4854\n",
      "Epoch: 13, Batch: 37, Loss: 0.6778\n",
      "Epoch: 13, Batch: 38, Loss: 0.7017\n",
      "Epoch: 13, Batch: 39, Loss: 0.4554\n",
      "Epoch: 13, Batch: 40, Loss: 0.3031\n",
      "Epoch: 13, Batch: 41, Loss: 0.6172\n",
      "Epoch: 13, Batch: 42, Loss: 0.7357\n",
      "Epoch: 13, Batch: 43, Loss: 0.7133\n",
      "Epoch: 13, Batch: 44, Loss: 0.6084\n",
      "Epoch: 13, Batch: 45, Loss: 0.4365\n",
      "Epoch: 13, Batch: 46, Loss: 0.6911\n",
      "Epoch: 13, Batch: 47, Loss: 0.5412\n",
      "Epoch: 13, Batch: 48, Loss: 0.6131\n",
      "Epoch: 13, Batch: 49, Loss: 0.5987\n",
      "Epoch: 13, Batch: 50, Loss: 0.5875\n",
      "Epoch: 13, Batch: 51, Loss: 0.5824\n",
      "Epoch: 13, Batch: 52, Loss: 0.5304\n",
      "Epoch: 13, Batch: 53, Loss: 0.4408\n",
      "Epoch: 13, Batch: 54, Loss: 0.6178\n",
      "Epoch: 13, Batch: 55, Loss: 0.4828\n",
      "Epoch: 13, Batch: 56, Loss: 0.4124\n",
      "Epoch: 13, Batch: 57, Loss: 0.6087\n",
      "Epoch: 13, Batch: 58, Loss: 0.4812\n",
      "Epoch: 13, Batch: 59, Loss: 0.4997\n",
      "Epoch: 13, Batch: 60, Loss: 0.5638\n",
      "Epoch: 13, Batch: 61, Loss: 0.5572\n",
      "Epoch: 13, Batch: 62, Loss: 0.5757\n",
      "Epoch: 13, Batch: 63, Loss: 0.4522\n",
      "Epoch: 13, Batch: 64, Loss: 0.5402\n",
      "Epoch: 13, Batch: 65, Loss: 0.5789\n",
      "Epoch: 13, Batch: 66, Loss: 0.6424\n",
      "Epoch: 13, Batch: 67, Loss: 0.6431\n",
      "Epoch: 13, Batch: 68, Loss: 0.5631\n",
      "Epoch: 13, Batch: 69, Loss: 0.6528\n",
      "Epoch: 13, Batch: 70, Loss: 0.4429\n",
      "Epoch: 13, Batch: 71, Loss: 0.5510\n",
      "Epoch: 13, Batch: 72, Loss: 0.5081\n",
      "Epoch: 13, Batch: 73, Loss: 0.5590\n",
      "Epoch: 13, Batch: 74, Loss: 0.6295\n",
      "Epoch: 13, Batch: 75, Loss: 0.5805\n",
      "Epoch: 13, Batch: 76, Loss: 0.5043\n",
      "Epoch: 13, Batch: 77, Loss: 0.5959\n",
      "Epoch: 13, Batch: 78, Loss: 0.5927\n",
      "Epoch: 13, Batch: 79, Loss: 0.4325\n",
      "Epoch: 13, Batch: 80, Loss: 0.2851\n",
      "Epoch: 13, Batch: 81, Loss: 0.5337\n",
      "Epoch: 13, Batch: 82, Loss: 0.3316\n",
      "Epoch: 13, Batch: 83, Loss: 0.5936\n",
      "Epoch: 13, Batch: 84, Loss: 0.5594\n",
      "Epoch: 13, Batch: 85, Loss: 0.6383\n",
      "Epoch: 13, Batch: 86, Loss: 0.6162\n",
      "Epoch: 13, Batch: 87, Loss: 0.4909\n",
      "Epoch: 13, Batch: 88, Loss: 0.4826\n",
      "Epoch: 13, Batch: 89, Loss: 0.5865\n",
      "Epoch: 13, Batch: 90, Loss: 0.6323\n",
      "Epoch: 13, Batch: 91, Loss: 0.5737\n",
      "Epoch: 13, Batch: 92, Loss: 0.4014\n",
      "Epoch: 13, Batch: 93, Loss: 0.3866\n",
      "Epoch: 13, Batch: 94, Loss: 0.5608\n",
      "Epoch: 13, Batch: 95, Loss: 0.6850\n",
      "Epoch: 13, Batch: 96, Loss: 0.8141\n",
      "Epoch: 13, Batch: 97, Loss: 0.4476\n",
      "Epoch: 13, Batch: 98, Loss: 0.6470\n",
      "Epoch: 13, Batch: 99, Loss: 0.5541\n",
      "Epoch: 13, Batch: 100, Loss: 0.8256\n",
      "Epoch: 13, Batch: 101, Loss: 0.8236\n",
      "Epoch: 13, Batch: 102, Loss: 0.7883\n",
      "Epoch: 13, Batch: 103, Loss: 0.5663\n",
      "Epoch: 13, Batch: 104, Loss: 0.4641\n",
      "Epoch: 13, Batch: 105, Loss: 0.6617\n",
      "Epoch: 13, Batch: 106, Loss: 0.3739\n",
      "Epoch: 13, Batch: 107, Loss: 0.6034\n",
      "Epoch: 13, Batch: 108, Loss: 0.6687\n",
      "Epoch: 13, Batch: 109, Loss: 0.6061\n",
      "Epoch: 13, Batch: 110, Loss: 0.5067\n",
      "Epoch: 13, Batch: 111, Loss: 0.4407\n",
      "Epoch: 13, Batch: 112, Loss: 0.3876\n",
      "Epoch: 14, Batch: 0, Loss: 0.7404\n",
      "Epoch: 14, Batch: 1, Loss: 0.7385\n",
      "Epoch: 14, Batch: 2, Loss: 0.5179\n",
      "Epoch: 14, Batch: 3, Loss: 0.4790\n",
      "Epoch: 14, Batch: 4, Loss: 0.3986\n",
      "Epoch: 14, Batch: 5, Loss: 0.4783\n",
      "Epoch: 14, Batch: 6, Loss: 0.6200\n",
      "Epoch: 14, Batch: 7, Loss: 0.8476\n",
      "Epoch: 14, Batch: 8, Loss: 0.4191\n",
      "Epoch: 14, Batch: 9, Loss: 0.5625\n",
      "Epoch: 14, Batch: 10, Loss: 0.6571\n",
      "Epoch: 14, Batch: 11, Loss: 0.2818\n",
      "Epoch: 14, Batch: 12, Loss: 0.3554\n",
      "Epoch: 14, Batch: 13, Loss: 0.4487\n",
      "Epoch: 14, Batch: 14, Loss: 0.3799\n",
      "Epoch: 14, Batch: 15, Loss: 0.4720\n",
      "Epoch: 14, Batch: 16, Loss: 0.5888\n",
      "Epoch: 14, Batch: 17, Loss: 0.5731\n",
      "Epoch: 14, Batch: 18, Loss: 0.5806\n",
      "Epoch: 14, Batch: 19, Loss: 0.5245\n",
      "Epoch: 14, Batch: 20, Loss: 0.9018\n",
      "Epoch: 14, Batch: 21, Loss: 0.5427\n",
      "Epoch: 14, Batch: 22, Loss: 0.6126\n",
      "Epoch: 14, Batch: 23, Loss: 0.5235\n",
      "Epoch: 14, Batch: 24, Loss: 0.5367\n",
      "Epoch: 14, Batch: 25, Loss: 0.5960\n",
      "Epoch: 14, Batch: 26, Loss: 0.6671\n",
      "Epoch: 14, Batch: 27, Loss: 0.6892\n",
      "Epoch: 14, Batch: 28, Loss: 0.5551\n",
      "Epoch: 14, Batch: 29, Loss: 0.5547\n",
      "Epoch: 14, Batch: 30, Loss: 0.4832\n",
      "Epoch: 14, Batch: 31, Loss: 0.6572\n",
      "Epoch: 14, Batch: 32, Loss: 0.5604\n",
      "Epoch: 14, Batch: 33, Loss: 0.6683\n",
      "Epoch: 14, Batch: 34, Loss: 0.5780\n",
      "Epoch: 14, Batch: 35, Loss: 0.6105\n",
      "Epoch: 14, Batch: 36, Loss: 0.5190\n",
      "Epoch: 14, Batch: 37, Loss: 0.6529\n",
      "Epoch: 14, Batch: 38, Loss: 0.6197\n",
      "Epoch: 14, Batch: 39, Loss: 0.5042\n",
      "Epoch: 14, Batch: 40, Loss: 0.3078\n",
      "Epoch: 14, Batch: 41, Loss: 0.5726\n",
      "Epoch: 14, Batch: 42, Loss: 0.7022\n",
      "Epoch: 14, Batch: 43, Loss: 0.7195\n",
      "Epoch: 14, Batch: 44, Loss: 0.6179\n",
      "Epoch: 14, Batch: 45, Loss: 0.3767\n",
      "Epoch: 14, Batch: 46, Loss: 0.6834\n",
      "Epoch: 14, Batch: 47, Loss: 0.5557\n",
      "Epoch: 14, Batch: 48, Loss: 0.5917\n",
      "Epoch: 14, Batch: 49, Loss: 0.5887\n",
      "Epoch: 14, Batch: 50, Loss: 0.6192\n",
      "Epoch: 14, Batch: 51, Loss: 0.6064\n",
      "Epoch: 14, Batch: 52, Loss: 0.4751\n",
      "Epoch: 14, Batch: 53, Loss: 0.4344\n",
      "Epoch: 14, Batch: 54, Loss: 0.6886\n",
      "Epoch: 14, Batch: 55, Loss: 0.5067\n",
      "Epoch: 14, Batch: 56, Loss: 0.4262\n",
      "Epoch: 14, Batch: 57, Loss: 0.5715\n",
      "Epoch: 14, Batch: 58, Loss: 0.4656\n",
      "Epoch: 14, Batch: 59, Loss: 0.4613\n",
      "Epoch: 14, Batch: 60, Loss: 0.5433\n",
      "Epoch: 14, Batch: 61, Loss: 0.5454\n",
      "Epoch: 14, Batch: 62, Loss: 0.6409\n",
      "Epoch: 14, Batch: 63, Loss: 0.3971\n",
      "Epoch: 14, Batch: 64, Loss: 0.5494\n",
      "Epoch: 14, Batch: 65, Loss: 0.5709\n",
      "Epoch: 14, Batch: 66, Loss: 0.6112\n",
      "Epoch: 14, Batch: 67, Loss: 0.6593\n",
      "Epoch: 14, Batch: 68, Loss: 0.5703\n",
      "Epoch: 14, Batch: 69, Loss: 0.6234\n",
      "Epoch: 14, Batch: 70, Loss: 0.4419\n",
      "Epoch: 14, Batch: 71, Loss: 0.5024\n",
      "Epoch: 14, Batch: 72, Loss: 0.4537\n",
      "Epoch: 14, Batch: 73, Loss: 0.5524\n",
      "Epoch: 14, Batch: 74, Loss: 0.6480\n",
      "Epoch: 14, Batch: 75, Loss: 0.5270\n",
      "Epoch: 14, Batch: 76, Loss: 0.4770\n",
      "Epoch: 14, Batch: 77, Loss: 0.6089\n",
      "Epoch: 14, Batch: 78, Loss: 0.5295\n",
      "Epoch: 14, Batch: 79, Loss: 0.4500\n",
      "Epoch: 14, Batch: 80, Loss: 0.3024\n",
      "Epoch: 14, Batch: 81, Loss: 0.5295\n",
      "Epoch: 14, Batch: 82, Loss: 0.3616\n",
      "Epoch: 14, Batch: 83, Loss: 0.6310\n",
      "Epoch: 14, Batch: 84, Loss: 0.5931\n",
      "Epoch: 14, Batch: 85, Loss: 0.5764\n",
      "Epoch: 14, Batch: 86, Loss: 0.6031\n",
      "Epoch: 14, Batch: 87, Loss: 0.4702\n",
      "Epoch: 14, Batch: 88, Loss: 0.4297\n",
      "Epoch: 14, Batch: 89, Loss: 0.6062\n",
      "Epoch: 14, Batch: 90, Loss: 0.6467\n",
      "Epoch: 14, Batch: 91, Loss: 0.5394\n",
      "Epoch: 14, Batch: 92, Loss: 0.3672\n",
      "Epoch: 14, Batch: 93, Loss: 0.4391\n",
      "Epoch: 14, Batch: 94, Loss: 0.5566\n",
      "Epoch: 14, Batch: 95, Loss: 0.7035\n",
      "Epoch: 14, Batch: 96, Loss: 0.6846\n",
      "Epoch: 14, Batch: 97, Loss: 0.4867\n",
      "Epoch: 14, Batch: 98, Loss: 0.6840\n",
      "Epoch: 14, Batch: 99, Loss: 0.5285\n",
      "Epoch: 14, Batch: 100, Loss: 0.7928\n",
      "Epoch: 14, Batch: 101, Loss: 0.7640\n",
      "Epoch: 14, Batch: 102, Loss: 0.7639\n",
      "Epoch: 14, Batch: 103, Loss: 0.6227\n",
      "Epoch: 14, Batch: 104, Loss: 0.4039\n",
      "Epoch: 14, Batch: 105, Loss: 0.6922\n",
      "Epoch: 14, Batch: 106, Loss: 0.3517\n",
      "Epoch: 14, Batch: 107, Loss: 0.5861\n",
      "Epoch: 14, Batch: 108, Loss: 0.6371\n",
      "Epoch: 14, Batch: 109, Loss: 0.5570\n",
      "Epoch: 14, Batch: 110, Loss: 0.4575\n",
      "Epoch: 14, Batch: 111, Loss: 0.4578\n",
      "Epoch: 14, Batch: 112, Loss: 0.3724\n",
      "Epoch: 15, Batch: 0, Loss: 0.7163\n",
      "Epoch: 15, Batch: 1, Loss: 0.6924\n",
      "Epoch: 15, Batch: 2, Loss: 0.5002\n",
      "Epoch: 15, Batch: 3, Loss: 0.5029\n",
      "Epoch: 15, Batch: 4, Loss: 0.4136\n",
      "Epoch: 15, Batch: 5, Loss: 0.4999\n",
      "Epoch: 15, Batch: 6, Loss: 0.7161\n",
      "Epoch: 15, Batch: 7, Loss: 0.8724\n",
      "Epoch: 15, Batch: 8, Loss: 0.4739\n",
      "Epoch: 15, Batch: 9, Loss: 0.4902\n",
      "Epoch: 15, Batch: 10, Loss: 0.6266\n",
      "Epoch: 15, Batch: 11, Loss: 0.2467\n",
      "Epoch: 15, Batch: 12, Loss: 0.3726\n",
      "Epoch: 15, Batch: 13, Loss: 0.4388\n",
      "Epoch: 15, Batch: 14, Loss: 0.4242\n",
      "Epoch: 15, Batch: 15, Loss: 0.4509\n",
      "Epoch: 15, Batch: 16, Loss: 0.5207\n",
      "Epoch: 15, Batch: 17, Loss: 0.6168\n",
      "Epoch: 15, Batch: 18, Loss: 0.5579\n",
      "Epoch: 15, Batch: 19, Loss: 0.5322\n",
      "Epoch: 15, Batch: 20, Loss: 0.8449\n",
      "Epoch: 15, Batch: 21, Loss: 0.5204\n",
      "Epoch: 15, Batch: 22, Loss: 0.6477\n",
      "Epoch: 15, Batch: 23, Loss: 0.5750\n",
      "Epoch: 15, Batch: 24, Loss: 0.5041\n",
      "Epoch: 15, Batch: 25, Loss: 0.6388\n",
      "Epoch: 15, Batch: 26, Loss: 0.6917\n",
      "Epoch: 15, Batch: 27, Loss: 0.6629\n",
      "Epoch: 15, Batch: 28, Loss: 0.5488\n",
      "Epoch: 15, Batch: 29, Loss: 0.5234\n",
      "Epoch: 15, Batch: 30, Loss: 0.4938\n",
      "Epoch: 15, Batch: 31, Loss: 0.6258\n",
      "Epoch: 15, Batch: 32, Loss: 0.5467\n",
      "Epoch: 15, Batch: 33, Loss: 0.6907\n",
      "Epoch: 15, Batch: 34, Loss: 0.5309\n",
      "Epoch: 15, Batch: 35, Loss: 0.6322\n",
      "Epoch: 15, Batch: 36, Loss: 0.4964\n",
      "Epoch: 15, Batch: 37, Loss: 0.7232\n",
      "Epoch: 15, Batch: 38, Loss: 0.6317\n",
      "Epoch: 15, Batch: 39, Loss: 0.4318\n",
      "Epoch: 15, Batch: 40, Loss: 0.3436\n",
      "Epoch: 15, Batch: 41, Loss: 0.5156\n",
      "Epoch: 15, Batch: 42, Loss: 0.6989\n",
      "Epoch: 15, Batch: 43, Loss: 0.6899\n",
      "Epoch: 15, Batch: 44, Loss: 0.5817\n",
      "Epoch: 15, Batch: 45, Loss: 0.4169\n",
      "Epoch: 15, Batch: 46, Loss: 0.6384\n",
      "Epoch: 15, Batch: 47, Loss: 0.5229\n",
      "Epoch: 15, Batch: 48, Loss: 0.5794\n",
      "Epoch: 15, Batch: 49, Loss: 0.5696\n",
      "Epoch: 15, Batch: 50, Loss: 0.6609\n",
      "Epoch: 15, Batch: 51, Loss: 0.5952\n",
      "Epoch: 15, Batch: 52, Loss: 0.5090\n",
      "Epoch: 15, Batch: 53, Loss: 0.4483\n",
      "Epoch: 15, Batch: 54, Loss: 0.7084\n",
      "Epoch: 15, Batch: 55, Loss: 0.5233\n",
      "Epoch: 15, Batch: 56, Loss: 0.4232\n",
      "Epoch: 15, Batch: 57, Loss: 0.5551\n",
      "Epoch: 15, Batch: 58, Loss: 0.4771\n",
      "Epoch: 15, Batch: 59, Loss: 0.4585\n",
      "Epoch: 15, Batch: 60, Loss: 0.5246\n",
      "Epoch: 15, Batch: 61, Loss: 0.5157\n",
      "Epoch: 15, Batch: 62, Loss: 0.6236\n",
      "Epoch: 15, Batch: 63, Loss: 0.4050\n",
      "Epoch: 15, Batch: 64, Loss: 0.5446\n",
      "Epoch: 15, Batch: 65, Loss: 0.6252\n",
      "Epoch: 15, Batch: 66, Loss: 0.6497\n",
      "Epoch: 15, Batch: 67, Loss: 0.7027\n",
      "Epoch: 15, Batch: 68, Loss: 0.5383\n",
      "Epoch: 15, Batch: 69, Loss: 0.6595\n",
      "Epoch: 15, Batch: 70, Loss: 0.4240\n",
      "Epoch: 15, Batch: 71, Loss: 0.5241\n",
      "Epoch: 15, Batch: 72, Loss: 0.5012\n",
      "Epoch: 15, Batch: 73, Loss: 0.4925\n",
      "Epoch: 15, Batch: 74, Loss: 0.6885\n",
      "Epoch: 15, Batch: 75, Loss: 0.5226\n",
      "Epoch: 15, Batch: 76, Loss: 0.4733\n",
      "Epoch: 15, Batch: 77, Loss: 0.6902\n",
      "Epoch: 15, Batch: 78, Loss: 0.5653\n",
      "Epoch: 15, Batch: 79, Loss: 0.4290\n",
      "Epoch: 15, Batch: 80, Loss: 0.3135\n",
      "Epoch: 15, Batch: 81, Loss: 0.5050\n",
      "Epoch: 15, Batch: 82, Loss: 0.3272\n",
      "Epoch: 15, Batch: 83, Loss: 0.6216\n",
      "Epoch: 15, Batch: 84, Loss: 0.6044\n",
      "Epoch: 15, Batch: 85, Loss: 0.6203\n",
      "Epoch: 15, Batch: 86, Loss: 0.5739\n",
      "Epoch: 15, Batch: 87, Loss: 0.4398\n",
      "Epoch: 15, Batch: 88, Loss: 0.4955\n",
      "Epoch: 15, Batch: 89, Loss: 0.5462\n",
      "Epoch: 15, Batch: 90, Loss: 0.6039\n",
      "Epoch: 15, Batch: 91, Loss: 0.4908\n",
      "Epoch: 15, Batch: 92, Loss: 0.3801\n",
      "Epoch: 15, Batch: 93, Loss: 0.4225\n",
      "Epoch: 15, Batch: 94, Loss: 0.5679\n",
      "Epoch: 15, Batch: 95, Loss: 0.6894\n",
      "Epoch: 15, Batch: 96, Loss: 0.7629\n",
      "Epoch: 15, Batch: 97, Loss: 0.4374\n",
      "Epoch: 15, Batch: 98, Loss: 0.6999\n",
      "Epoch: 15, Batch: 99, Loss: 0.4911\n",
      "Epoch: 15, Batch: 100, Loss: 0.7686\n",
      "Epoch: 15, Batch: 101, Loss: 0.7972\n",
      "Epoch: 15, Batch: 102, Loss: 0.7885\n",
      "Epoch: 15, Batch: 103, Loss: 0.5487\n",
      "Epoch: 15, Batch: 104, Loss: 0.4063\n",
      "Epoch: 15, Batch: 105, Loss: 0.6561\n",
      "Epoch: 15, Batch: 106, Loss: 0.3871\n",
      "Epoch: 15, Batch: 107, Loss: 0.5622\n",
      "Epoch: 15, Batch: 108, Loss: 0.5983\n",
      "Epoch: 15, Batch: 109, Loss: 0.5967\n",
      "Epoch: 15, Batch: 110, Loss: 0.5052\n",
      "Epoch: 15, Batch: 111, Loss: 0.4425\n",
      "Epoch: 15, Batch: 112, Loss: 0.4354\n",
      "Epoch: 16, Batch: 0, Loss: 0.7152\n",
      "Epoch: 16, Batch: 1, Loss: 0.7048\n",
      "Epoch: 16, Batch: 2, Loss: 0.5169\n",
      "Epoch: 16, Batch: 3, Loss: 0.4681\n",
      "Epoch: 16, Batch: 4, Loss: 0.4043\n",
      "Epoch: 16, Batch: 5, Loss: 0.4622\n",
      "Epoch: 16, Batch: 6, Loss: 0.7677\n",
      "Epoch: 16, Batch: 7, Loss: 0.8517\n",
      "Epoch: 16, Batch: 8, Loss: 0.4514\n",
      "Epoch: 16, Batch: 9, Loss: 0.5144\n",
      "Epoch: 16, Batch: 10, Loss: 0.6478\n",
      "Epoch: 16, Batch: 11, Loss: 0.2636\n",
      "Epoch: 16, Batch: 12, Loss: 0.4065\n",
      "Epoch: 16, Batch: 13, Loss: 0.4342\n",
      "Epoch: 16, Batch: 14, Loss: 0.4265\n",
      "Epoch: 16, Batch: 15, Loss: 0.4996\n",
      "Epoch: 16, Batch: 16, Loss: 0.5255\n",
      "Epoch: 16, Batch: 17, Loss: 0.5923\n",
      "Epoch: 16, Batch: 18, Loss: 0.5634\n",
      "Epoch: 16, Batch: 19, Loss: 0.4851\n",
      "Epoch: 16, Batch: 20, Loss: 0.8482\n",
      "Epoch: 16, Batch: 21, Loss: 0.5325\n",
      "Epoch: 16, Batch: 22, Loss: 0.5709\n",
      "Epoch: 16, Batch: 23, Loss: 0.4737\n",
      "Epoch: 16, Batch: 24, Loss: 0.5161\n",
      "Epoch: 16, Batch: 25, Loss: 0.5794\n",
      "Epoch: 16, Batch: 26, Loss: 0.6258\n",
      "Epoch: 16, Batch: 27, Loss: 0.7362\n",
      "Epoch: 16, Batch: 28, Loss: 0.5750\n",
      "Epoch: 16, Batch: 29, Loss: 0.5267\n",
      "Epoch: 16, Batch: 30, Loss: 0.4500\n",
      "Epoch: 16, Batch: 31, Loss: 0.6435\n",
      "Epoch: 16, Batch: 32, Loss: 0.5609\n",
      "Epoch: 16, Batch: 33, Loss: 0.7638\n",
      "Epoch: 16, Batch: 34, Loss: 0.5263\n",
      "Epoch: 16, Batch: 35, Loss: 0.6241\n",
      "Epoch: 16, Batch: 36, Loss: 0.4961\n",
      "Epoch: 16, Batch: 37, Loss: 0.6478\n",
      "Epoch: 16, Batch: 38, Loss: 0.6031\n",
      "Epoch: 16, Batch: 39, Loss: 0.4956\n",
      "Epoch: 16, Batch: 40, Loss: 0.3041\n",
      "Epoch: 16, Batch: 41, Loss: 0.5215\n",
      "Epoch: 16, Batch: 42, Loss: 0.7279\n",
      "Epoch: 16, Batch: 43, Loss: 0.6904\n",
      "Epoch: 16, Batch: 44, Loss: 0.5840\n",
      "Epoch: 16, Batch: 45, Loss: 0.3682\n",
      "Epoch: 16, Batch: 46, Loss: 0.6316\n",
      "Epoch: 16, Batch: 47, Loss: 0.5203\n",
      "Epoch: 16, Batch: 48, Loss: 0.6241\n",
      "Epoch: 16, Batch: 49, Loss: 0.6000\n",
      "Epoch: 16, Batch: 50, Loss: 0.6549\n",
      "Epoch: 16, Batch: 51, Loss: 0.6425\n",
      "Epoch: 16, Batch: 52, Loss: 0.4458\n",
      "Epoch: 16, Batch: 53, Loss: 0.4880\n",
      "Epoch: 16, Batch: 54, Loss: 0.7081\n",
      "Epoch: 16, Batch: 55, Loss: 0.5144\n",
      "Epoch: 16, Batch: 56, Loss: 0.4002\n",
      "Epoch: 16, Batch: 57, Loss: 0.4836\n",
      "Epoch: 16, Batch: 58, Loss: 0.4345\n",
      "Epoch: 16, Batch: 59, Loss: 0.4573\n",
      "Epoch: 16, Batch: 60, Loss: 0.5745\n",
      "Epoch: 16, Batch: 61, Loss: 0.5437\n",
      "Epoch: 16, Batch: 62, Loss: 0.6131\n",
      "Epoch: 16, Batch: 63, Loss: 0.3806\n",
      "Epoch: 16, Batch: 64, Loss: 0.5362\n",
      "Epoch: 16, Batch: 65, Loss: 0.6067\n",
      "Epoch: 16, Batch: 66, Loss: 0.6080\n",
      "Epoch: 16, Batch: 67, Loss: 0.6705\n",
      "Epoch: 16, Batch: 68, Loss: 0.5565\n",
      "Epoch: 16, Batch: 69, Loss: 0.6360\n",
      "Epoch: 16, Batch: 70, Loss: 0.4656\n",
      "Epoch: 16, Batch: 71, Loss: 0.4502\n",
      "Epoch: 16, Batch: 72, Loss: 0.4942\n",
      "Epoch: 16, Batch: 73, Loss: 0.5330\n",
      "Epoch: 16, Batch: 74, Loss: 0.6428\n",
      "Epoch: 16, Batch: 75, Loss: 0.5460\n",
      "Epoch: 16, Batch: 76, Loss: 0.4686\n",
      "Epoch: 16, Batch: 77, Loss: 0.7155\n",
      "Epoch: 16, Batch: 78, Loss: 0.5550\n",
      "Epoch: 16, Batch: 79, Loss: 0.4743\n",
      "Epoch: 16, Batch: 80, Loss: 0.3233\n",
      "Epoch: 16, Batch: 81, Loss: 0.5157\n",
      "Epoch: 16, Batch: 82, Loss: 0.3540\n",
      "Epoch: 16, Batch: 83, Loss: 0.6672\n",
      "Epoch: 16, Batch: 84, Loss: 0.6324\n",
      "Epoch: 16, Batch: 85, Loss: 0.5961\n",
      "Epoch: 16, Batch: 86, Loss: 0.6344\n",
      "Epoch: 16, Batch: 87, Loss: 0.4836\n",
      "Epoch: 16, Batch: 88, Loss: 0.4738\n",
      "Epoch: 16, Batch: 89, Loss: 0.5718\n",
      "Epoch: 16, Batch: 90, Loss: 0.7317\n",
      "Epoch: 16, Batch: 91, Loss: 0.4968\n",
      "Epoch: 16, Batch: 92, Loss: 0.4149\n",
      "Epoch: 16, Batch: 93, Loss: 0.4209\n",
      "Epoch: 16, Batch: 94, Loss: 0.5466\n",
      "Epoch: 16, Batch: 95, Loss: 0.7148\n",
      "Epoch: 16, Batch: 96, Loss: 0.7823\n",
      "Epoch: 16, Batch: 97, Loss: 0.5514\n",
      "Epoch: 16, Batch: 98, Loss: 0.6702\n",
      "Epoch: 16, Batch: 99, Loss: 0.5664\n",
      "Epoch: 16, Batch: 100, Loss: 0.7571\n",
      "Epoch: 16, Batch: 101, Loss: 0.8484\n",
      "Epoch: 16, Batch: 102, Loss: 0.8149\n",
      "Epoch: 16, Batch: 103, Loss: 0.5168\n",
      "Epoch: 16, Batch: 104, Loss: 0.4095\n",
      "Epoch: 16, Batch: 105, Loss: 0.6293\n",
      "Epoch: 16, Batch: 106, Loss: 0.3940\n",
      "Epoch: 16, Batch: 107, Loss: 0.5408\n",
      "Epoch: 16, Batch: 108, Loss: 0.6943\n",
      "Epoch: 16, Batch: 109, Loss: 0.6413\n",
      "Epoch: 16, Batch: 110, Loss: 0.5102\n",
      "Epoch: 16, Batch: 111, Loss: 0.4243\n",
      "Epoch: 16, Batch: 112, Loss: 0.3701\n",
      "Epoch: 17, Batch: 0, Loss: 0.7100\n",
      "Epoch: 17, Batch: 1, Loss: 0.7153\n",
      "Epoch: 17, Batch: 2, Loss: 0.5519\n",
      "Epoch: 17, Batch: 3, Loss: 0.4301\n",
      "Epoch: 17, Batch: 4, Loss: 0.3980\n",
      "Epoch: 17, Batch: 5, Loss: 0.4364\n",
      "Epoch: 17, Batch: 6, Loss: 0.6919\n",
      "Epoch: 17, Batch: 7, Loss: 0.7953\n",
      "Epoch: 17, Batch: 8, Loss: 0.4701\n",
      "Epoch: 17, Batch: 9, Loss: 0.5647\n",
      "Epoch: 17, Batch: 10, Loss: 0.6210\n",
      "Epoch: 17, Batch: 11, Loss: 0.2936\n",
      "Epoch: 17, Batch: 12, Loss: 0.4043\n",
      "Epoch: 17, Batch: 13, Loss: 0.4081\n",
      "Epoch: 17, Batch: 14, Loss: 0.3928\n",
      "Epoch: 17, Batch: 15, Loss: 0.5308\n",
      "Epoch: 17, Batch: 16, Loss: 0.5293\n",
      "Epoch: 17, Batch: 17, Loss: 0.5602\n",
      "Epoch: 17, Batch: 18, Loss: 0.6107\n",
      "Epoch: 17, Batch: 19, Loss: 0.4642\n",
      "Epoch: 17, Batch: 20, Loss: 0.8745\n",
      "Epoch: 17, Batch: 21, Loss: 0.4541\n",
      "Epoch: 17, Batch: 22, Loss: 0.6063\n",
      "Epoch: 17, Batch: 23, Loss: 0.4924\n",
      "Epoch: 17, Batch: 24, Loss: 0.5860\n",
      "Epoch: 17, Batch: 25, Loss: 0.5362\n",
      "Epoch: 17, Batch: 26, Loss: 0.5507\n",
      "Epoch: 17, Batch: 27, Loss: 0.7007\n",
      "Epoch: 17, Batch: 28, Loss: 0.6016\n",
      "Epoch: 17, Batch: 29, Loss: 0.5365\n",
      "Epoch: 17, Batch: 30, Loss: 0.4270\n",
      "Epoch: 17, Batch: 31, Loss: 0.6740\n",
      "Epoch: 17, Batch: 32, Loss: 0.5639\n",
      "Epoch: 17, Batch: 33, Loss: 0.7352\n",
      "Epoch: 17, Batch: 34, Loss: 0.5254\n",
      "Epoch: 17, Batch: 35, Loss: 0.6014\n",
      "Epoch: 17, Batch: 36, Loss: 0.5196\n",
      "Epoch: 17, Batch: 37, Loss: 0.6311\n",
      "Epoch: 17, Batch: 38, Loss: 0.5558\n",
      "Epoch: 17, Batch: 39, Loss: 0.4428\n",
      "Epoch: 17, Batch: 40, Loss: 0.3268\n",
      "Epoch: 17, Batch: 41, Loss: 0.5420\n",
      "Epoch: 17, Batch: 42, Loss: 0.7162\n",
      "Epoch: 17, Batch: 43, Loss: 0.6310\n",
      "Epoch: 17, Batch: 44, Loss: 0.5405\n",
      "Epoch: 17, Batch: 45, Loss: 0.3460\n",
      "Epoch: 17, Batch: 46, Loss: 0.6322\n",
      "Epoch: 17, Batch: 47, Loss: 0.5366\n",
      "Epoch: 17, Batch: 48, Loss: 0.6306\n",
      "Epoch: 17, Batch: 49, Loss: 0.5577\n",
      "Epoch: 17, Batch: 50, Loss: 0.6657\n",
      "Epoch: 17, Batch: 51, Loss: 0.6240\n",
      "Epoch: 17, Batch: 52, Loss: 0.4687\n",
      "Epoch: 17, Batch: 53, Loss: 0.4284\n",
      "Epoch: 17, Batch: 54, Loss: 0.6699\n",
      "Epoch: 17, Batch: 55, Loss: 0.5327\n",
      "Epoch: 17, Batch: 56, Loss: 0.4106\n",
      "Epoch: 17, Batch: 57, Loss: 0.5185\n",
      "Epoch: 17, Batch: 58, Loss: 0.4439\n",
      "Epoch: 17, Batch: 59, Loss: 0.4763\n",
      "Epoch: 17, Batch: 60, Loss: 0.5478\n",
      "Epoch: 17, Batch: 61, Loss: 0.5125\n",
      "Epoch: 17, Batch: 62, Loss: 0.6429\n",
      "Epoch: 17, Batch: 63, Loss: 0.3766\n",
      "Epoch: 17, Batch: 64, Loss: 0.5807\n",
      "Epoch: 17, Batch: 65, Loss: 0.6102\n",
      "Epoch: 17, Batch: 66, Loss: 0.6552\n",
      "Epoch: 17, Batch: 67, Loss: 0.5963\n",
      "Epoch: 17, Batch: 68, Loss: 0.5227\n",
      "Epoch: 17, Batch: 69, Loss: 0.6690\n",
      "Epoch: 17, Batch: 70, Loss: 0.4462\n",
      "Epoch: 17, Batch: 71, Loss: 0.4630\n",
      "Epoch: 17, Batch: 72, Loss: 0.4877\n",
      "Epoch: 17, Batch: 73, Loss: 0.5695\n",
      "Epoch: 17, Batch: 74, Loss: 0.6044\n",
      "Epoch: 17, Batch: 75, Loss: 0.5414\n",
      "Epoch: 17, Batch: 76, Loss: 0.4335\n",
      "Epoch: 17, Batch: 77, Loss: 0.6076\n",
      "Epoch: 17, Batch: 78, Loss: 0.6408\n",
      "Epoch: 17, Batch: 79, Loss: 0.4356\n",
      "Epoch: 17, Batch: 80, Loss: 0.3080\n",
      "Epoch: 17, Batch: 81, Loss: 0.4675\n",
      "Epoch: 17, Batch: 82, Loss: 0.3612\n",
      "Epoch: 17, Batch: 83, Loss: 0.6155\n",
      "Epoch: 17, Batch: 84, Loss: 0.5491\n",
      "Epoch: 17, Batch: 85, Loss: 0.5494\n",
      "Epoch: 17, Batch: 86, Loss: 0.6053\n",
      "Epoch: 17, Batch: 87, Loss: 0.4534\n",
      "Epoch: 17, Batch: 88, Loss: 0.4379\n",
      "Epoch: 17, Batch: 89, Loss: 0.6072\n",
      "Epoch: 17, Batch: 90, Loss: 0.6476\n",
      "Epoch: 17, Batch: 91, Loss: 0.5336\n",
      "Epoch: 17, Batch: 92, Loss: 0.3937\n",
      "Epoch: 17, Batch: 93, Loss: 0.3929\n",
      "Epoch: 17, Batch: 94, Loss: 0.5594\n",
      "Epoch: 17, Batch: 95, Loss: 0.7562\n",
      "Epoch: 17, Batch: 96, Loss: 0.7641\n",
      "Epoch: 17, Batch: 97, Loss: 0.4707\n",
      "Epoch: 17, Batch: 98, Loss: 0.7306\n",
      "Epoch: 17, Batch: 99, Loss: 0.5162\n",
      "Epoch: 17, Batch: 100, Loss: 0.8219\n",
      "Epoch: 17, Batch: 101, Loss: 0.8335\n",
      "Epoch: 17, Batch: 102, Loss: 0.7721\n",
      "Epoch: 17, Batch: 103, Loss: 0.5260\n",
      "Epoch: 17, Batch: 104, Loss: 0.3832\n",
      "Epoch: 17, Batch: 105, Loss: 0.7029\n",
      "Epoch: 17, Batch: 106, Loss: 0.3694\n",
      "Epoch: 17, Batch: 107, Loss: 0.5883\n",
      "Epoch: 17, Batch: 108, Loss: 0.6587\n",
      "Epoch: 17, Batch: 109, Loss: 0.6579\n",
      "Epoch: 17, Batch: 110, Loss: 0.4529\n",
      "Epoch: 17, Batch: 111, Loss: 0.4325\n",
      "Epoch: 17, Batch: 112, Loss: 0.3976\n",
      "Epoch: 18, Batch: 0, Loss: 0.7096\n",
      "Epoch: 18, Batch: 1, Loss: 0.7411\n",
      "Epoch: 18, Batch: 2, Loss: 0.5487\n",
      "Epoch: 18, Batch: 3, Loss: 0.4365\n",
      "Epoch: 18, Batch: 4, Loss: 0.3705\n",
      "Epoch: 18, Batch: 5, Loss: 0.4570\n",
      "Epoch: 18, Batch: 6, Loss: 0.7173\n",
      "Epoch: 18, Batch: 7, Loss: 0.8475\n",
      "Epoch: 18, Batch: 8, Loss: 0.4714\n",
      "Epoch: 18, Batch: 9, Loss: 0.4808\n",
      "Epoch: 18, Batch: 10, Loss: 0.6835\n",
      "Epoch: 18, Batch: 11, Loss: 0.2713\n",
      "Epoch: 18, Batch: 12, Loss: 0.4011\n",
      "Epoch: 18, Batch: 13, Loss: 0.3926\n",
      "Epoch: 18, Batch: 14, Loss: 0.4170\n",
      "Epoch: 18, Batch: 15, Loss: 0.5003\n",
      "Epoch: 18, Batch: 16, Loss: 0.4968\n",
      "Epoch: 18, Batch: 17, Loss: 0.5136\n",
      "Epoch: 18, Batch: 18, Loss: 0.5265\n",
      "Epoch: 18, Batch: 19, Loss: 0.5292\n",
      "Epoch: 18, Batch: 20, Loss: 0.8504\n",
      "Epoch: 18, Batch: 21, Loss: 0.4903\n",
      "Epoch: 18, Batch: 22, Loss: 0.6119\n",
      "Epoch: 18, Batch: 23, Loss: 0.4920\n",
      "Epoch: 18, Batch: 24, Loss: 0.5487\n",
      "Epoch: 18, Batch: 25, Loss: 0.5457\n",
      "Epoch: 18, Batch: 26, Loss: 0.6239\n",
      "Epoch: 18, Batch: 27, Loss: 0.7130\n",
      "Epoch: 18, Batch: 28, Loss: 0.4815\n",
      "Epoch: 18, Batch: 29, Loss: 0.5276\n",
      "Epoch: 18, Batch: 30, Loss: 0.4628\n",
      "Epoch: 18, Batch: 31, Loss: 0.6927\n",
      "Epoch: 18, Batch: 32, Loss: 0.5701\n",
      "Epoch: 18, Batch: 33, Loss: 0.7721\n",
      "Epoch: 18, Batch: 34, Loss: 0.4993\n",
      "Epoch: 18, Batch: 35, Loss: 0.6501\n",
      "Epoch: 18, Batch: 36, Loss: 0.5264\n",
      "Epoch: 18, Batch: 37, Loss: 0.6185\n",
      "Epoch: 18, Batch: 38, Loss: 0.5714\n",
      "Epoch: 18, Batch: 39, Loss: 0.4414\n",
      "Epoch: 18, Batch: 40, Loss: 0.2874\n",
      "Epoch: 18, Batch: 41, Loss: 0.5362\n",
      "Epoch: 18, Batch: 42, Loss: 0.7198\n",
      "Epoch: 18, Batch: 43, Loss: 0.7146\n",
      "Epoch: 18, Batch: 44, Loss: 0.5121\n",
      "Epoch: 18, Batch: 45, Loss: 0.3884\n",
      "Epoch: 18, Batch: 46, Loss: 0.6425\n",
      "Epoch: 18, Batch: 47, Loss: 0.5478\n",
      "Epoch: 18, Batch: 48, Loss: 0.6392\n",
      "Epoch: 18, Batch: 49, Loss: 0.6183\n",
      "Epoch: 18, Batch: 50, Loss: 0.6345\n",
      "Epoch: 18, Batch: 51, Loss: 0.5852\n",
      "Epoch: 18, Batch: 52, Loss: 0.4555\n",
      "Epoch: 18, Batch: 53, Loss: 0.4368\n",
      "Epoch: 18, Batch: 54, Loss: 0.7032\n",
      "Epoch: 18, Batch: 55, Loss: 0.5319\n",
      "Epoch: 18, Batch: 56, Loss: 0.3208\n",
      "Epoch: 18, Batch: 57, Loss: 0.4679\n",
      "Epoch: 18, Batch: 58, Loss: 0.4621\n",
      "Epoch: 18, Batch: 59, Loss: 0.4625\n",
      "Epoch: 18, Batch: 60, Loss: 0.5349\n",
      "Epoch: 18, Batch: 61, Loss: 0.5006\n",
      "Epoch: 18, Batch: 62, Loss: 0.5651\n",
      "Epoch: 18, Batch: 63, Loss: 0.3581\n",
      "Epoch: 18, Batch: 64, Loss: 0.5096\n",
      "Epoch: 18, Batch: 65, Loss: 0.6521\n",
      "Epoch: 18, Batch: 66, Loss: 0.6525\n",
      "Epoch: 18, Batch: 67, Loss: 0.5937\n",
      "Epoch: 18, Batch: 68, Loss: 0.5793\n",
      "Epoch: 18, Batch: 69, Loss: 0.6303\n",
      "Epoch: 18, Batch: 70, Loss: 0.5013\n",
      "Epoch: 18, Batch: 71, Loss: 0.4465\n",
      "Epoch: 18, Batch: 72, Loss: 0.4979\n",
      "Epoch: 18, Batch: 73, Loss: 0.5823\n",
      "Epoch: 18, Batch: 74, Loss: 0.5719\n",
      "Epoch: 18, Batch: 75, Loss: 0.5638\n",
      "Epoch: 18, Batch: 76, Loss: 0.4224\n",
      "Epoch: 18, Batch: 77, Loss: 0.5850\n",
      "Epoch: 18, Batch: 78, Loss: 0.5484\n",
      "Epoch: 18, Batch: 79, Loss: 0.4530\n",
      "Epoch: 18, Batch: 80, Loss: 0.3283\n",
      "Epoch: 18, Batch: 81, Loss: 0.4926\n",
      "Epoch: 18, Batch: 82, Loss: 0.3326\n",
      "Epoch: 18, Batch: 83, Loss: 0.6393\n",
      "Epoch: 18, Batch: 84, Loss: 0.6279\n",
      "Epoch: 18, Batch: 85, Loss: 0.6037\n",
      "Epoch: 18, Batch: 86, Loss: 0.6289\n",
      "Epoch: 18, Batch: 87, Loss: 0.5075\n",
      "Epoch: 18, Batch: 88, Loss: 0.4354\n",
      "Epoch: 18, Batch: 89, Loss: 0.5518\n",
      "Epoch: 18, Batch: 90, Loss: 0.6377\n",
      "Epoch: 18, Batch: 91, Loss: 0.4988\n",
      "Epoch: 18, Batch: 92, Loss: 0.3734\n",
      "Epoch: 18, Batch: 93, Loss: 0.3716\n",
      "Epoch: 18, Batch: 94, Loss: 0.5439\n",
      "Epoch: 18, Batch: 95, Loss: 0.7259\n",
      "Epoch: 18, Batch: 96, Loss: 0.7892\n",
      "Epoch: 18, Batch: 97, Loss: 0.4379\n",
      "Epoch: 18, Batch: 98, Loss: 0.6467\n",
      "Epoch: 18, Batch: 99, Loss: 0.5265\n",
      "Epoch: 18, Batch: 100, Loss: 0.8389\n",
      "Epoch: 18, Batch: 101, Loss: 0.8788\n",
      "Epoch: 18, Batch: 102, Loss: 0.6994\n",
      "Epoch: 18, Batch: 103, Loss: 0.5269\n",
      "Epoch: 18, Batch: 104, Loss: 0.4079\n",
      "Epoch: 18, Batch: 105, Loss: 0.6350\n",
      "Epoch: 18, Batch: 106, Loss: 0.3419\n",
      "Epoch: 18, Batch: 107, Loss: 0.5958\n",
      "Epoch: 18, Batch: 108, Loss: 0.6506\n",
      "Epoch: 18, Batch: 109, Loss: 0.6423\n",
      "Epoch: 18, Batch: 110, Loss: 0.4948\n",
      "Epoch: 18, Batch: 111, Loss: 0.4444\n",
      "Epoch: 18, Batch: 112, Loss: 0.3983\n",
      "Epoch: 19, Batch: 0, Loss: 0.7032\n",
      "Epoch: 19, Batch: 1, Loss: 0.6695\n",
      "Epoch: 19, Batch: 2, Loss: 0.5243\n",
      "Epoch: 19, Batch: 3, Loss: 0.4232\n",
      "Epoch: 19, Batch: 4, Loss: 0.4008\n",
      "Epoch: 19, Batch: 5, Loss: 0.4530\n",
      "Epoch: 19, Batch: 6, Loss: 0.6886\n",
      "Epoch: 19, Batch: 7, Loss: 0.7729\n",
      "Epoch: 19, Batch: 8, Loss: 0.4683\n",
      "Epoch: 19, Batch: 9, Loss: 0.5059\n",
      "Epoch: 19, Batch: 10, Loss: 0.6286\n",
      "Epoch: 19, Batch: 11, Loss: 0.2432\n",
      "Epoch: 19, Batch: 12, Loss: 0.3907\n",
      "Epoch: 19, Batch: 13, Loss: 0.4328\n",
      "Epoch: 19, Batch: 14, Loss: 0.4408\n",
      "Epoch: 19, Batch: 15, Loss: 0.4909\n",
      "Epoch: 19, Batch: 16, Loss: 0.4978\n",
      "Epoch: 19, Batch: 17, Loss: 0.5044\n",
      "Epoch: 19, Batch: 18, Loss: 0.5735\n",
      "Epoch: 19, Batch: 19, Loss: 0.4442\n",
      "Epoch: 19, Batch: 20, Loss: 0.8287\n",
      "Epoch: 19, Batch: 21, Loss: 0.4501\n",
      "Epoch: 19, Batch: 22, Loss: 0.6187\n",
      "Epoch: 19, Batch: 23, Loss: 0.4776\n",
      "Epoch: 19, Batch: 24, Loss: 0.4994\n",
      "Epoch: 19, Batch: 25, Loss: 0.5619\n",
      "Epoch: 19, Batch: 26, Loss: 0.6401\n",
      "Epoch: 19, Batch: 27, Loss: 0.7158\n",
      "Epoch: 19, Batch: 28, Loss: 0.5437\n",
      "Epoch: 19, Batch: 29, Loss: 0.5316\n",
      "Epoch: 19, Batch: 30, Loss: 0.4577\n",
      "Epoch: 19, Batch: 31, Loss: 0.7239\n",
      "Epoch: 19, Batch: 32, Loss: 0.5828\n",
      "Epoch: 19, Batch: 33, Loss: 0.7506\n",
      "Epoch: 19, Batch: 34, Loss: 0.4614\n",
      "Epoch: 19, Batch: 35, Loss: 0.6229\n",
      "Epoch: 19, Batch: 36, Loss: 0.5349\n",
      "Epoch: 19, Batch: 37, Loss: 0.6996\n",
      "Epoch: 19, Batch: 38, Loss: 0.5405\n",
      "Epoch: 19, Batch: 39, Loss: 0.4570\n",
      "Epoch: 19, Batch: 40, Loss: 0.2947\n",
      "Epoch: 19, Batch: 41, Loss: 0.5318\n",
      "Epoch: 19, Batch: 42, Loss: 0.6525\n",
      "Epoch: 19, Batch: 43, Loss: 0.6549\n",
      "Epoch: 19, Batch: 44, Loss: 0.5692\n",
      "Epoch: 19, Batch: 45, Loss: 0.3469\n",
      "Epoch: 19, Batch: 46, Loss: 0.6545\n",
      "Epoch: 19, Batch: 47, Loss: 0.5334\n",
      "Epoch: 19, Batch: 48, Loss: 0.6373\n",
      "Epoch: 19, Batch: 49, Loss: 0.5409\n",
      "Epoch: 19, Batch: 50, Loss: 0.6486\n",
      "Epoch: 19, Batch: 51, Loss: 0.6006\n",
      "Epoch: 19, Batch: 52, Loss: 0.4637\n",
      "Epoch: 19, Batch: 53, Loss: 0.4457\n",
      "Epoch: 19, Batch: 54, Loss: 0.6937\n",
      "Epoch: 19, Batch: 55, Loss: 0.4816\n",
      "Epoch: 19, Batch: 56, Loss: 0.3508\n",
      "Epoch: 19, Batch: 57, Loss: 0.4554\n",
      "Epoch: 19, Batch: 58, Loss: 0.4817\n",
      "Epoch: 19, Batch: 59, Loss: 0.4691\n",
      "Epoch: 19, Batch: 60, Loss: 0.5876\n",
      "Epoch: 19, Batch: 61, Loss: 0.5120\n",
      "Epoch: 19, Batch: 62, Loss: 0.6459\n",
      "Epoch: 19, Batch: 63, Loss: 0.4010\n",
      "Epoch: 19, Batch: 64, Loss: 0.5003\n",
      "Epoch: 19, Batch: 65, Loss: 0.6597\n",
      "Epoch: 19, Batch: 66, Loss: 0.6174\n",
      "Epoch: 19, Batch: 67, Loss: 0.6908\n",
      "Epoch: 19, Batch: 68, Loss: 0.5010\n",
      "Epoch: 19, Batch: 69, Loss: 0.6625\n",
      "Epoch: 19, Batch: 70, Loss: 0.4330\n",
      "Epoch: 19, Batch: 71, Loss: 0.4523\n",
      "Epoch: 19, Batch: 72, Loss: 0.4558\n",
      "Epoch: 19, Batch: 73, Loss: 0.5787\n",
      "Epoch: 19, Batch: 74, Loss: 0.5300\n",
      "Epoch: 19, Batch: 75, Loss: 0.5286\n",
      "Epoch: 19, Batch: 76, Loss: 0.4312\n",
      "Epoch: 19, Batch: 77, Loss: 0.6173\n",
      "Epoch: 19, Batch: 78, Loss: 0.6133\n",
      "Epoch: 19, Batch: 79, Loss: 0.4273\n",
      "Epoch: 19, Batch: 80, Loss: 0.2864\n",
      "Epoch: 19, Batch: 81, Loss: 0.5066\n",
      "Epoch: 19, Batch: 82, Loss: 0.3395\n",
      "Epoch: 19, Batch: 83, Loss: 0.6542\n",
      "Epoch: 19, Batch: 84, Loss: 0.5900\n",
      "Epoch: 19, Batch: 85, Loss: 0.5686\n",
      "Epoch: 19, Batch: 86, Loss: 0.6253\n",
      "Epoch: 19, Batch: 87, Loss: 0.4825\n",
      "Epoch: 19, Batch: 88, Loss: 0.4581\n",
      "Epoch: 19, Batch: 89, Loss: 0.5414\n",
      "Epoch: 19, Batch: 90, Loss: 0.5609\n",
      "Epoch: 19, Batch: 91, Loss: 0.4501\n",
      "Epoch: 19, Batch: 92, Loss: 0.3771\n",
      "Epoch: 19, Batch: 93, Loss: 0.4084\n",
      "Epoch: 19, Batch: 94, Loss: 0.5720\n",
      "Epoch: 19, Batch: 95, Loss: 0.7782\n",
      "Epoch: 19, Batch: 96, Loss: 0.7449\n",
      "Epoch: 19, Batch: 97, Loss: 0.5231\n",
      "Epoch: 19, Batch: 98, Loss: 0.6199\n",
      "Epoch: 19, Batch: 99, Loss: 0.5468\n",
      "Epoch: 19, Batch: 100, Loss: 0.8498\n",
      "Epoch: 19, Batch: 101, Loss: 0.8485\n",
      "Epoch: 19, Batch: 102, Loss: 0.6815\n",
      "Epoch: 19, Batch: 103, Loss: 0.5146\n",
      "Epoch: 19, Batch: 104, Loss: 0.3506\n",
      "Epoch: 19, Batch: 105, Loss: 0.5639\n",
      "Epoch: 19, Batch: 106, Loss: 0.3415\n",
      "Epoch: 19, Batch: 107, Loss: 0.5950\n",
      "Epoch: 19, Batch: 108, Loss: 0.7040\n",
      "Epoch: 19, Batch: 109, Loss: 0.6521\n",
      "Epoch: 19, Batch: 110, Loss: 0.4690\n",
      "Epoch: 19, Batch: 111, Loss: 0.4654\n",
      "Epoch: 19, Batch: 112, Loss: 0.3913\n"
     ]
    }
   ],
   "source": [
    "model=VIT_Couple().to('cuda')\n",
    "# new_model=VIT_Couple().to('cuda')\n",
    "# new_model.load_state_dict(torch.load('version_test3.pth'))\n",
    "# optimizer = torch.optim.SGD(new_model.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                  lr=1e-4, weight_decay=1e-3)\n",
    "for epoch in range(20):\n",
    "    train(model, train_loader, optimizer, epoch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted tensor([1, 1, 0, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 0, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "6\n",
      "predicted tensor([0, 1, 0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "4\n",
      "predicted tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 1, 1, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 0, 1, 1, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "9\n",
      "predicted tensor([0, 0, 0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "10\n",
      "predicted tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "labels tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "9\n",
      "predicted tensor([1, 1, 0, 0, 0, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 1, 0, 0, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "5\n",
      "predicted tensor([0, 1, 0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "6\n",
      "predicted tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 1, 0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "6\n",
      "predicted tensor([1, 0, 0, 1, 1, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 1, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "9\n",
      "predicted tensor([0, 1, 0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 0, 0, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 1, 1, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 1, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "9\n",
      "predicted tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 1, 1, 0, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "6\n",
      "predicted tensor([1, 1, 0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "5\n",
      "predicted tensor([1, 0, 1, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 1, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "6\n",
      "predicted tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([0, 1, 0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "4\n",
      "predicted tensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 1, 0, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 0, 0, 1, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 0, 1, 1, 1, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 1, 1, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "9\n",
      "predicted tensor([0, 1, 1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "6\n",
      "predicted tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 0, 1, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "5\n",
      "predicted tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 0, 1, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 0, 1, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 1, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "6\n",
      "predicted tensor([0, 1, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "labels tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 1, 1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 0, 1, 0, 1, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 1, 0, 0, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "6\n",
      "predicted tensor([1, 0, 1, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 1, 1, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "9\n",
      "predicted tensor([0, 1, 0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "9\n",
      "predicted tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 1, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 0, 1, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "5\n",
      "predicted tensor([1, 0, 0, 0, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 0, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 1, 0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 1, 0, 1, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "5\n",
      "predicted tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "10\n",
      "predicted tensor([1, 1, 1, 0, 1, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 1, 1, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "6\n",
      "predicted tensor([1, 1, 0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 0, 0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 1, 0, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "9\n",
      "predicted tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "9\n",
      "predicted tensor([1, 0, 1, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 1, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 0, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 0, 1, 1, 0, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 1, 0, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 0, 0, 0, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 1, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "6\n",
      "predicted tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "10\n",
      "predicted tensor([0, 1, 0, 1, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 1, 1, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "6\n",
      "predicted tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 1, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "6\n",
      "predicted tensor([1, 1, 0, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 0, 1, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 1, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 1, 0, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "9\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "9\n",
      "predicted tensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 1, 1, 0, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "9\n",
      "predicted tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 0, 1, 0, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 1, 0, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 0, 0, 1, 0, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 1, 0, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "9\n",
      "predicted tensor([1, 1, 0, 0, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 1, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 0, 1, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 1, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 0, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 0, 1, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "9\n",
      "predicted tensor([0, 1, 0, 0, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 0, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "10\n",
      "predicted tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 1, 0, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 1, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 1, 0, 1, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "6\n",
      "predicted tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 1, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 0, 1, 1, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 1, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 1], device='cuda:0')\n",
      "6\n",
      "predicted tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 0, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 0, 0, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "10\n",
      "predicted tensor([1, 0, 0, 1, 0, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 1, 0, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "9\n",
      "predicted tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "9\n",
      "predicted tensor([1, 0, 0, 1, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "5\n",
      "predicted tensor([0, 0, 1, 1, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 0, 1, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "6\n",
      "predicted tensor([0, 0, 1, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 1, 0, 1, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 1, 0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 1, 0, 1, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "5\n",
      "predicted tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 1, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "5\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 1, 0, 0, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 1, 0, 1, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "8\n",
      "predicted tensor([0, 1, 1, 1, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "9\n",
      "predicted tensor([1, 0, 0, 1, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([1, 0, 1, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "9\n",
      "predicted tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 0, 0, 0, 1, 1, 1, 0, 1, 0], device='cuda:0')\n",
      "6\n",
      "predicted tensor([0, 0, 1, 1, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "labels tensor([0, 1, 1, 1, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([0, 0, 0, 1, 1, 1, 0, 1, 1, 1], device='cuda:0')\n",
      "labels tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "8\n",
      "predicted tensor([1, 1, 1, 1, 0, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "labels tensor([1, 1, 0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "7\n",
      "predicted tensor([1, 0], device='cuda:0')\n",
      "labels tensor([1, 0], device='cuda:0')\n",
      "2\n",
      "830\n",
      "1122\n",
      "Accuracy: 73.98%\n"
     ]
    }
   ],
   "source": [
    "# new_model=VIT_Couple().to('cuda')\n",
    "# new_model.load_state_dict(torch.load('version_test3.pth'))\n",
    "test(model, test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'version_test4.pth')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#base:80epoch:56.14"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
